{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4cdb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (13.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from faker) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from faker) (4.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from python-dateutil>=2.4->faker) (1.15.0)\n",
      "Requirement already satisfied: uszipcode==0.2.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.2.6)\n",
      "Requirement already satisfied: SQLAlchemy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from uszipcode==0.2.6) (1.3.23)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from uszipcode==0.2.6) (20.3.0)\n",
      "Requirement already satisfied: pathlib-mate in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from uszipcode==0.2.6) (1.0.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from uszipcode==0.2.6) (2.26.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pathlib-mate->uszipcode==0.2.6) (1.15.0)\n",
      "Requirement already satisfied: autopep8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pathlib-mate->uszipcode==0.2.6) (1.5.5)\n",
      "Requirement already satisfied: atomicwrites in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pathlib-mate->uszipcode==0.2.6) (1.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->uszipcode==0.2.6) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->uszipcode==0.2.6) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->uszipcode==0.2.6) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->uszipcode==0.2.6) (3.1)\n",
      "Requirement already satisfied: pycodestyle>=2.6.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from autopep8->pathlib-mate->uszipcode==0.2.6) (2.6.0)\n",
      "Requirement already satisfied: toml in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from autopep8->pathlib-mate->uszipcode==0.2.6) (0.10.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker\n",
    "!pip install uszipcode==0.2.6\n",
    "\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine(simple_zipcode=False)\n",
    "fake = Faker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139cd00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_lst = [\"Southeast Medical Center\", \"Marshall Medical Center\", \"Coffee Memorial Hospital\", \n",
    "           \"Mizell Memorial Hospital\", \"Crenshaw Community Hospital\", \"St Vincent's East\", \n",
    "           \"Dekalb Medical Center\",\"Baptist Medical Center\", \"Callahan Eye Hospital\", \n",
    "           \"Keller Memorial Hospital\", \"Dale Medical Center\", \"Cherokee Medical Center\", \"Medical Center South\",\n",
    "           \"Jackson Hospital & Clinic Inc\", \"East Medical Center\", \"Tanner Medical Center-east\", \n",
    "           \"University Of Harvard Hospital\", \"Community Hospital Inc\", \"Cullman Regional Medical Center\",\n",
    "           \"Andalusia Health\", \"Stringfellow Memorial Hospital\", \"Boston Hospital\",\n",
    "           \"Gadsden Regional Medical Center\",\"Marion Regional Medical Center\", \"New York Medical Center\",\n",
    "           \"Riverview Medical Center\", \"Georgian Medical Center\", \"Medical Center Enterprise\", \n",
    "           \"Greene County Hospital\", \"Lake Community Hospital\",\"Flowers Hospital\", \"St Vincent\", \n",
    "           \"San Burnadino Medical Center\", \"Lawrence Medical Center\", \"Highlands Medical Center\", \n",
    "           \"Wiregrass Medical Center\", \"Russell Medical Center\", \"Medical Center Barbour\", \"Clay Hospital\",\n",
    "           \"Northeast Regional Medical Center\", \"Limestone Hospital\", \"South Regional Medical Center\", \n",
    "           \"Decatur Morgan Hospital\", \"Northwest Medical Center\", \"University Of South Medical Center\", \n",
    "           \"Walker Medical Center\",\"Providence Hospital\", \"Grove Hill Memorial Hospital\",\n",
    "           \"Regional Medical Center\", \"Hale County Hospital\", \"Elmore Community Hospital\", \n",
    "           \"McMillan Memorial Hospital\", \"Thomas Hospital\", \"Citizens Medical Center\", \"Jones Hospital\",\n",
    "           \"Princeton Medical Center\", \"Grandview Medical Center\", \"Prattville Hospital\", \n",
    "           \"Pickens Medical Center\", \"Bullock Hospital\", \"Whitfield Memorial Hospital\", \n",
    "           \"Infirmary Medical Center\", \"Medical West\", \"Regional Medical Center Parkway Campus\", \n",
    "           \"Monroe Hospital\", \"Lakeland Community Hospital\", \"Troy Regional Medical Center\", \n",
    "           \"Jackson Medical Center\", \"North Baldwin Infirmary\", \"St Vincent's St Clair\", \n",
    "           \"Crestwood Medical Center\", \"Hill Hospital\", \"Brookwood Medical Center\", \"Springhill Memorial Hospital\",\n",
    "           \"Rmc Jacksonville\", \"Evergreen Medical Center\",\"Baptist Medical Center East\", \"Stabler Memorial Hospital\",\n",
    "           \"Shoals Hospital\", \"Russellville Hospital\",\"Coosa Valley Medical Center\", \"Arizona Medical Center\",\n",
    "           \"Jack Hughston Memorial Hospital\", \"Atmore Community Hospital\",\"St Vincent's Chilton\", \n",
    "           \"Washington County Hospital\", \"Red Bay Hospital\", \"Choctaw General Hospital\",\"St Vincents Blount\", \n",
    "           \"Children's Hospital\", \"University Children's And Women's Hospital\",\"Providence Medical Center\", \n",
    "           \"Mat-su Regional Medical Center\", \"Bartlett Regional Hospital\", \"Banner Medical Center\", \n",
    "           \"Fairbanks Memorial Hospital\", \"Alaska Hospital\", \"Yukon Reg Hospital\", \"Mountain Hospital\",\n",
    "           \"Pennsylvania General Hospital\", \"Alaska Medical Center\", \"Valdez Medical Center\", \"Seward Hospital\", \n",
    "           \"Community Hospital\", \"Petersburg Medical Center\", \"Wrangell Medical Center\", \"Peninsula Hospital\",\n",
    "           \"Providence Medical Ctr\", \"Cordova Community Medical Center\", \"Norton Regional Hospital\", \n",
    "           \"Sinai Hospital\", \"Milan Health Center\", \"Ketchikan Medical Center\", \"Samuel Memorial Hospital\"]\n",
    "\n",
    "state_lst = ['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IA', 'ID', 'IL', 'IN', 'KS',\n",
    "             'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', \n",
    "             'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']\n",
    "\n",
    "\n",
    "ordered_col_lst =[\"ClaimID\", \"CapEpcIndicator\", \"SubscriberID\", \"SubscriberFName\", \"SubscriberMName\",\n",
    "                  \"SubscriberLName\", \"SubscriberDOB\", \"SubscriberGender\", \"SubscriberAddressLine1\",\n",
    "                  \"SubscriberAddressLine2\", \"SubscriberCity\", \"SubscriberState\", \"SubscriberZipCode\", \"PatientID\", \n",
    "                  \"PatientRelationship\", \"PatientFName\", \"PatientMName\", \"PatientLName\",\"PatientDOB\", \"PatientGender\",\n",
    "                  \"PatientAddressLine1\", \"PatientAddressLine2\", \"PatientCity\",\"PatientState\", \"PatientZipCode\", \n",
    "                  \"GroupNumber\", \"GroupName\", \"BillingProviderID\",\"BillingProviderNPI\", \"BillingProviderTIN\", \n",
    "                  \"BillingProviderSpecialtyCode\", \"BillingProviderTaxonomy\", \"BillingProviderOrg\",\n",
    "                  \"BillingProviderFName\",\"BillingProviderMName\", \"BillingProviderLName\", \"BillingProviderEntityType\",\n",
    "                  \"BillingProviderAddressLine1\", \"BillingProviderAddressLine2\", \"BillingProviderCity\", \n",
    "                  \"BillingProviderState\", \"BillingProviderZipCode\", \"BillingProviderPhoneNumber\",\n",
    "                  \"CertifyingPhysicianID\", \"CertifyingPhysicianFName\", \"CertifyingPhysicianMName\",\n",
    "                  \"CertifyingPhysicianLName\", \"CertifyingPhysicianNPI\", \"OrderingProviderID\",\"OrderingProviderNPI\",\n",
    "                  \"OrderingProviderTIN\", \"OrderingProviderSpecialtyCode\",\"OrderingProviderTaxonomy\", \n",
    "                  \"OrderingProviderOrg\", \"OrderingProviderFName\",\"OrderingProviderMName\", \"OrderingProviderLName\",\n",
    "                  \"OrderingProviderAddressLine1\",\"OrderingProviderAddressLine2\", \"OrderingProviderCity\", \n",
    "                  \"OrderingProviderState\", \"OrderingProviderZipCode\", \"OrderingProviderPhoneNumber\",\n",
    "                  \"ReferringProviderNPI\", \"InterPlan\", \"LineOfBusiness\", \"ClaimPaidDate\", \"ClaimReceivedDate\",\n",
    "                  \"ClaimServiceEndDate\",\"ClaimServiceStartDate\", \"ClaimAdjustmentCode\", \"ClaimAdjustmentReasonCode\",\n",
    "                  \"PriorClaimID\",\"ASOFlag\", \"PrimaryFlag\", \"ClaimStatusCategoryCode\", \"ClaimType\", \"ContractedFlag\",\n",
    "                  \"HdrCharges\", \"HdrCOBPay\", \"HdrPatientCopay\", \"HdrPatientPay\", \"HdrPay\", \"HdrPayerPay\",\"CLIA\", \n",
    "                  \"DropOffZipCode\", \"PickUpZipCode\", \"RelatedCausesCode\", \"AccidentDate\",\"EmergencyIndicator\",\n",
    "                  \"LineNumber\", \"NumofAdjustments\", \"LineAmountCoinsurance\",\"LineAmountCopay\", \"LineAmountDeductible\",\n",
    "                  \"LineCharges\", \"LinePayerPaid\", \"LineCOBPay\",\"LineTotPaid\", \"LineProcCode\", \"LineUnits\",\n",
    "                  \"LineUnitType\", \"LineConsideredAmount\", \"LineAllowedAmount\", \"MOD1\", \"MOD2\", \"MOD3\", \"MOD4\", \"MOD5\",\n",
    "                  \"MOD6\", \"ICDVersion\", \"LinePOS\",\"LineServiceEndDate\", \"LineServiceStartDate\", \n",
    "                  \"LineServiceStatusCategoryCode\",\"LineAdjustmentCode\", \"LineAdjustmentReasonCode\",\n",
    "                  \"RenderingProviderID\", \"RenderingProviderNPI\", \"RenderingProviderTIN\",\n",
    "                  \"RenderingProviderSpecialtyCode\",\"RenderingProviderTaxonomy\", \"RenderingProviderOrg\", \n",
    "                  \"RenderingProviderFName\",\"RenderingProviderMName\", \"RenderingProviderLName\", \n",
    "                  \"RenderingProviderEntityType\", \"RenderingProviderAddressLine1\", \"RenderingProviderAddressLine2\", \n",
    "                  \"RenderingProviderCity\",\"RenderingProviderState\", \"RenderingProviderZipCode\",\n",
    "                  \"RenderingProviderPhoneNumber\", \"OutOfNetwork\", \"PreAuthIndicator\", \"PreAuthNumber\", \"NDC\", \n",
    "                  \"DenyFlag\", \"DenyReason\", \"ClaimDeletionInd\", \"ToothNumber\", \"ToothBegin\", \"ToothEnd\",\n",
    "                  \"ToothSurfaces\", \"RelatedHospAdmitDate\", \"RelatedHospDischargeDate\", \"AdmitType\", \"AdmitSource\", \n",
    "                  \"DischargeStatus\", \"DRGCode\", \"DRGVersion\", \"AdmittingDiag\", \"ICDProc1\", \"ICDProc2\",\"ICDProc3\",\n",
    "                  \"ICDProc4\", \"ICDProcDate1\", \"ICDProcDate2\", \"ICDProcDate3\", \"ICDProcDate4\", \"APCCode\", \"CCN\",\n",
    "                  \"AttendingProviderNAME\", \"AttendingProviderNPI\", \"OtherPhysicianNAME\",\"OtherPhysicianNPI\", \n",
    "                  \"RevenueCode\", \"TypeofBill\", \"HCPC_Rate_HIPPSCode\", \"OccurrenceCode\",\"HIPPSCode\", \"AdmitDate\", \n",
    "                  \"ValueCode\", \"ConditionCode\", \"Diag1\", \"Diag2\", \"Diag3\", \"Diag4\",\"Diag5\", \"Diag6\", \"Diag7\", \"Diag8\",\n",
    "                  \"Diag9\", \"Diag10\", \"Diag11\", \"Diag12\", \"Diag13\", \"Diag14\", \"Diag15\", \"Diag16\", \"Diag17\", \"Diag18\",\n",
    "                  \"Diag19\", \"Diag20\", \"Diag21\", \"Diag22\", \"Diag23\", \"Diag24\", \"Diag25\", \"ICDProc5\", \"ICDProc6\",\n",
    "                  \"ICDProc7\", \"ICDProc8\", \"ICDProc9\",\"ICDProc10\", \"ICDProc11\", \"ICDProc12\", \"ICDProc13\", \"ICDProc14\",\n",
    "                  \"ICDProc15\", \"ICDProc16\", \"ICDProc17\", \"ICDProc18\", \"ICDProc19\", \"ICDProc20\", \"ICDProc21\",\n",
    "                  \"ICDProc22\", \"ICDProc23\", \"ICDProc24\", \"ICDProc25\", \"ICDProcDate5\", \"ICDProcDate6\", \"ICDProcDate7\",\n",
    "                  \"ICDProcDate8\",\"ICDProcDate9\", \"ICDProcDate10\", \"ICDProcDate11\", \"ICDProcDate12\", \"ICDProcDate13\", \n",
    "                  \"ICDProcDate14\", \"ICDProcDate15\", \"ICDProcDate16\", \"ICDProcDate17\", \"ICDProcDate18\", \n",
    "                  \"ICDProcDate19\", \"ICDProcDate20\", \"ICDProcDate21\", \"ICDProcDate22\", \"ICDProcDate23\",\"ICDProcDate24\",\n",
    "                  \"ICDProcDate25\"]\n",
    "\n",
    "default_pat = ('758 Nunez Stravenue@Apt. 340@8463@AK@1933-03-17@99547@Other@Robert@Sarah@Henderson@Spouse@Elderly'\n",
    "        '@758 Nunez Stravenue@Apt. 340@8321@AK@1933-11-30@99547@Male@Bryan@Victor@Henderson')\n",
    "\n",
    "null_list = ['CertifyingPhysicianName', \"CertifyingPhysicianID\", \"CertifyingPhysicianNPI\", \"HCPC_Rate_HIPPSCode\",\n",
    "            \"CertifyingPhysicianNPI\", \"CertifyingPhysicianID\", \"OrderingProviderID\", 'OrderingProviderName', \n",
    "            \"OrderingProviderID\", \"OrderingProviderNPI\", \"PrescribingProviderSpecialtyCode\",\"ClaimStatusCategoryCode\",\n",
    "            'AttendingProviderNAME', \"AttendingProviderNPI\", \"PrescribingProviderID\", \"PrescribingProviderTIN\", \n",
    "            \"PrescribingProviderOrg\", 'PrescribingProviderFName', 'PrescribingProviderMName', \n",
    "            'PrescribingProviderLName', 'PrescribingProviderPhoneNumber', 'PrescribingProviderAddressLine1', \n",
    "            \"PrescribingProviderAddressLine2\", 'PrescribingProviderCity', 'PrescribingProviderID', \n",
    "            'PrescribingProviderTIN', \"PrescribingProviderTaxonomy\", \"PrimaryFlag\", \"LineConsideredAmount\", \n",
    "            \"PreAuthNumber\", \"PriorClaimID\", \"LineAdjustmentReasonCode\", \"RelatedHospDischargeDate\", \"DRGCode\"\n",
    "            \"RelatedHospAdmitDate\", \"ClaimAdjustmentReasonCode\", \"NDC\", \"LineAllowedAmount\", \"DenyReason\", \n",
    "            \"ConditionCode\", \"ValueCode\", \"ServiceUnits\", \"LineUnitType\", \"CLIA\", \"OccurrenceCode\", \"DRGVersion\",\n",
    "            \"OtherPhysicianNPI\", \"AdmitSource\", \"AdmitType\", \"DischargeStatus\", 'OtherPhysicianNAME', \"HIPPSCode\", \n",
    "            \"EmergencyIndicator\", \"AdmittingDiag\", \"ICDProcDate1\", \"ICDProcDate2\", \"ICDProcDate3\", \"ICDProcDate4\",\n",
    "            \"ICDProc1\", \"ICDProc2\", \"ICDProc3\", \"ICDProc4\", \"HIPPSCode\", \"ClaimStatusCategoryCode\",\"ICDProc4\",\n",
    "            \"HCPC_Rate_HIPPSCode\", \"DRGCode\", \"RevenueCode\", \"TypeofBill\", \"EmergencyIndicator\", \"AdmittingDiag\",\n",
    "            \"ICDProcDate1\", \"ICDProcDate2\", \"ICDProcDate3\", \"ICDProcDate4\", \"ICDProc1\", \"ICDProc2\", \"ICDProc3\", \n",
    "            'CertifyingPhysicianFName', 'CertifyingPhysicianMName', 'CertifyingPhysicianLName', 'OrderingProviderTIN',\n",
    "            'OrderingProviderSpecialtyCode', 'OrderingProviderTaxonomy', 'OrderingProviderOrg',\n",
    "            'OrderingProviderFName', 'OrderingProviderMName', 'OrderingProviderLName', 'OrderingProviderAddressLine1',\n",
    "            'OrderingProviderAddressLine2', 'OrderingProviderCity', 'OrderingProviderState','ClaimDeletionInd',\n",
    "            'OrderingProviderZipCode', 'OrderingProviderPhoneNumber', 'ClaimAdjustmentCode', 'DropOffZipCode', \n",
    "            'PickUpZipCode', 'BillingLineUnits', 'MOD1', 'MOD2', 'MOD3', 'MOD4', 'MOD5', 'MOD6', 'Diag1', 'Diag2',\n",
    "            'Diag3', 'Diag4', 'Diag5', 'Diag6', 'Diag7', 'Diag8', 'Diag9', 'Diag10', 'Diag11', 'Diag12', 'Diag13', \n",
    "            'Diag14', 'Diag15', 'Diag16', 'Diag17', 'Diag18', 'Diag19', 'Diag20', 'Diag21', 'Diag22', 'Diag23',\n",
    "            'Diag24', 'Diag25', 'LinePOS', 'LineServiceStatusCategoryCode', 'LineAdjustmentCode', 'ICDProc5',\n",
    "            'ICDProc6', 'ICDProc7', 'ICDProc8', 'ICDProc9', 'ICDProc10', 'ICDProc11', 'ICDProc12', 'ICDProc13',\n",
    "            'ICDProc14', 'ICDProc15', 'ICDProc16', 'ICDProc17', 'ICDProc18', 'ICDProc19', 'ICDProc20', 'ICDProc21',\n",
    "            'ICDProc22', 'ICDProc23', 'ICDProc24', 'ICDProc25', 'ICDProcDate5', 'ICDProcDate6', 'ICDProcDate7',\n",
    "            'ICDProcDate8', 'ICDProcDate9', 'ICDProcDate10', 'ICDProcDate11', 'ICDProcDate12', 'ICDProcDate13', \n",
    "            'ICDProcDate14', 'ICDProcDate15', 'ICDProcDate16', 'ICDProcDate17', 'ICDProcDate18', 'ICDProcDate19', \n",
    "            'ICDProcDate20', 'ICDProcDate21', 'ICDProcDate22', 'ICDProcDate23', 'ICDProcDate24', 'ICDProcDate25']\n",
    "\n",
    "pat_lst = ['PatientAddressLine1', 'PatientAddressLine2', 'PatientID', 'PatientState', 'PatientDOB', 'PatientZipCode',\n",
    "           'PatientGender', 'PatientFName', 'PatientMName', 'PatientLName', 'PatientRelationship', 'age_bin',\n",
    "           'SubscriberAddressLine1', 'SubscriberAddressLine2', 'SubscriberID', 'SubscriberState', 'SubscriberDOB', \n",
    "           'SubscriberZipCode', 'SubscriberGender','SubscriberFName', 'SubscriberMName', 'SubscriberLName']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0862b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcode(x):\n",
    "    return search.by_zipcode(x).city\n",
    "######################################################################################################################\n",
    "def in_network(x):\n",
    "    if x ==\"PAR\":\n",
    "        return \"N\"\n",
    "    return \"Y\"\n",
    "######################################################################################################################\n",
    "def getLastValue(aList):\n",
    "    return aList[-1]\n",
    "######################################################################################################################\n",
    "def pat_states(final_df):\n",
    "    dfs = []\n",
    "    final_out = pd.DataFrame()\n",
    "    for st in state_lst: \n",
    "        final_df_st = final_df\n",
    "        strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Patients/\"+st+\".csv\")\n",
    "        pat_df = pd.read_csv(strOutFile)\n",
    "        \n",
    "        pat_df[\"PatientID\"] = pat_df[\"PatientID\"].astype(str)\n",
    "        pat_df[\"SubscriberID\"] = pat_df[\"SubscriberID\"].astype(str)\n",
    "        pat_df[\"PatientZipCode\"] = pat_df[\"PatientZipCode\"].astype(str)\n",
    "        pat_df[\"SubscriberZipCode\"] = pat_df[\"SubscriberZipCode\"].astype(str)\n",
    "        pat_df[\"Pat\"] = (pat_df['PatientAddressLine1'] +'@'+pat_df['PatientAddressLine2'] +'@'+pat_df['PatientID'] +'@'+pat_df['PatientState'] +'@'+pat_df['PatientDOB'] +'@'+pat_df['PatientZipCode'] +'@'+pat_df['PatientGender'] +'@'+pat_df['PatientFName'] +'@'+pat_df['PatientMName']+'@'+pat_df['PatientLName'] +'@'+pat_df['PatientRelationship'] +'@'+pat_df['age_bin']+'@'+pat_df['SubscriberAddressLine1'] +'@'+pat_df['SubscriberAddressLine2'] +'@'+pat_df['SubscriberID']+'@'+pat_df['SubscriberState'] +'@'+pat_df['SubscriberDOB'] +'@'+pat_df['SubscriberZipCode']+'@'+pat_df['SubscriberGender'] +'@'+pat_df['SubscriberFName'] +'@'+pat_df['SubscriberMName'])\n",
    "        pat_df[\"Pat\"] = pat_df[\"Pat\"].astype(str)\n",
    "        adult_df = pat_df.loc[(pat_df['age_bin'] == 'Adult')]\n",
    "        adult_df_m = adult_df.loc[(adult_df['PatientGender'] == 'Male')]\n",
    "        adult_df_f = adult_df.loc[(adult_df['PatientGender'] == 'Female')]\n",
    "        adult_df_o = adult_df.loc[(adult_df['PatientGender'] == 'Other')]\n",
    "        \n",
    "        elderly_df = pat_df.loc[(pat_df['age_bin'] == 'Elderly')]    \n",
    "        elderly_df_m = elderly_df.loc[(elderly_df['PatientGender'] == 'Male')]\n",
    "        elderly_df_f = elderly_df.loc[(elderly_df['PatientGender'] == 'Female')]\n",
    "        elderly_df_o = elderly_df.loc[(elderly_df['PatientGender'] == 'Other')]\n",
    "\n",
    "        minor_df = pat_df.loc[(pat_df['age_bin'] == 'Minor')]\n",
    "        minor_df_m = minor_df.loc[(minor_df['PatientGender'] == 'Male')]\n",
    "        minor_df_f = minor_df.loc[(minor_df['PatientGender'] == 'Female')]\n",
    "        minor_df_o = minor_df.loc[(minor_df['PatientGender'] == 'Other')]\n",
    "\n",
    "        adult_list_m = adult_df_m[\"Pat\"].tolist()\n",
    "        adult_list_f = adult_df_f[\"Pat\"].tolist()\n",
    "        adult_list_o = adult_df_o[\"Pat\"].tolist()\n",
    "\n",
    "        elderly_list_m = elderly_df_m[\"Pat\"].tolist()\n",
    "        elderly_list_f = elderly_df_f[\"Pat\"].tolist()\n",
    "        elderly_list_o = elderly_df_o[\"Pat\"].tolist()\n",
    "\n",
    "        minor_list_m = minor_df_m[\"Pat\"].tolist()\n",
    "        minor_list_f = minor_df_f[\"Pat\"].tolist()\n",
    "        minor_list_o = minor_df_o[\"Pat\"].tolist()\n",
    "        \n",
    "        \n",
    "        minor_list_m= [x for x in minor_list_m if x != \"nan\"]\n",
    "        minor_list_f= [x for x in minor_list_f if x != \"nan\"]\n",
    "        minor_list_o= [x for x in minor_list_o if x != \"nan\"]\n",
    "        \n",
    "        adult_list_m= [x for x in adult_list_m if x != \"nan\"]\n",
    "        adult_list_f= [x for x in adult_list_f if x != \"nan\"]\n",
    "        adult_list_o= [x for x in adult_list_o if x != \"nan\"]\n",
    "  \n",
    "        elderly_list_m= [x for x in elderly_list_m if x != \"nan\"]\n",
    "        elderly_list_f= [x for x in elderly_list_f if x != \"nan\"]\n",
    "        elderly_list_o= [x for x in elderly_list_o if x != \"nan\"]\n",
    "        \n",
    "        minor_list_m.append(default_pat)\n",
    "        minor_list_f.append(default_pat)\n",
    "        minor_list_o.append(default_pat)\n",
    "        adult_list_m.append(default_pat)\n",
    "        adult_list_f.append(default_pat)\n",
    "        adult_list_o.append(default_pat)\n",
    "        elderly_list_m.append(default_pat)\n",
    "        elderly_list_f.append(default_pat)\n",
    "        elderly_list_o.append(default_pat)\n",
    "        \n",
    "        final_df_st = final_df.loc[(final_df['SubscriberState'] == st)]\n",
    "        if st == \"GA\":\n",
    "            final_df_null = final_df.loc[(final_df['SubscriberState'] == \"0.0\")]\n",
    "            final_df_st = final_df_st.append(final_df_null)\n",
    "        final_df_st = final_df_st.reset_index(drop = True)\n",
    "        if final_df_st.shape[0]==0:\n",
    "            continue\n",
    "        adult_df = final_df_st[(final_df_st['age_bin'] == 'Adult')]\n",
    "        adult_df_m = adult_df[(adult_df['pat_gender'] == 'M')]\n",
    "        adult_df_f = adult_df.loc[(adult_df['pat_gender'] == 'F')]\n",
    "        adult_df_o = adult_df.loc[(adult_df['pat_gender'] == 'None')]\n",
    "        \n",
    "        adult_df_m[\"Pat\"] = np.random.choice(adult_list_m, size=adult_df_m.shape[0])\n",
    "        adult_df_f[\"Pat\"] = np.random.choice(adult_list_f, size=adult_df_f.shape[0])\n",
    "        adult_df_o[\"Pat\"] = np.random.choice(adult_list_o, size=adult_df_o.shape[0])\n",
    "        \n",
    "        elderly_df = final_df_st.loc[(final_df_st['age_bin'] == 'Elderly')]\n",
    "        elderly_df_m = elderly_df.loc[(elderly_df['pat_gender'] == 'M')]\n",
    "        elderly_df_f = elderly_df.loc[(elderly_df['pat_gender'] == 'F')]\n",
    "        elderly_df_o = elderly_df.loc[(elderly_df['pat_gender'] == 'None')]\n",
    "        \n",
    "        elderly_df_m[\"Pat\"] = np.random.choice(elderly_list_m, size=elderly_df_m.shape[0])\n",
    "        elderly_df_f[\"Pat\"] = np.random.choice(elderly_list_f, size=elderly_df_f.shape[0])\n",
    "        elderly_df_o[\"Pat\"] = np.random.choice(elderly_list_o, size=elderly_df_o.shape[0])\n",
    "        \n",
    "        minor_df = final_df_st.loc[(final_df_st['age_bin'] == 'Minor')]\n",
    "        minor_df_m = minor_df.loc[(minor_df['pat_gender'] == 'M')]\n",
    "        minor_df_f = minor_df.loc[(minor_df['pat_gender'] == 'F')]\n",
    "        minor_df_o = minor_df.loc[(minor_df['pat_gender'] == 'None')]\n",
    "\n",
    "        minor_df_m[\"Pat\"] = np.random.choice(minor_list_m, size=minor_df_m.shape[0])\n",
    "        minor_df_f[\"Pat\"] = np.random.choice(minor_list_f, size=minor_df_f.shape[0])\n",
    "        minor_df_o[\"Pat\"] = np.random.choice(minor_list_o, size=minor_df_o.shape[0])\n",
    "        final_df_st = pd.concat([minor_df_m, minor_df_f, minor_df_o, elderly_df_m, elderly_df_f, elderly_df_o,\n",
    "                                 adult_df_f,adult_df_m, adult_df_o])\n",
    "        \n",
    "        final_out = final_out.append(final_df_st)\n",
    "    return final_out\n",
    "######################################################################################################################\n",
    "def claim_date(final_df):\n",
    "    two_y_ago = datetime.now().date() - relativedelta(years=2)\n",
    "    final_df[\"AccidentDate\"] = np.random.choice(pd.date_range(two_y_ago, datetime.now()- relativedelta(months=1)),\n",
    "                                                len(final_df))\n",
    "    delta = pd.to_timedelta(np.random.randint(0,4, size=len(final_df)), unit='d')\n",
    "    final_df[\"AdmitDate\"] = final_df[\"AccidentDate\"]+delta\n",
    "    delta = pd.to_timedelta(np.random.randint(0,3, size=len(final_df)), unit='d')\n",
    "    final_df[\"ClaimServiceStartDate\"] = final_df[\"AdmitDate\"] +delta\n",
    "    delta = pd.to_timedelta(np.random.randint(0,3, size=len(final_df)), unit='d')\n",
    "    final_df[\"LineServiceStartDate\"] = final_df[\"ClaimServiceStartDate\"]\n",
    "    final_df[\"LineServiceEndDate\"]=final_df[\"ClaimServiceStartDate\"]\n",
    "    final_df[\"ClaimServiceEndDate\"]=final_df[\"ClaimServiceStartDate\"]+delta \n",
    "    delta = pd.to_timedelta(np.random.randint(0,3, size=len(final_df)), unit='d')\n",
    "    final_df[\"ClaimReceivedDate\"] = final_df[\"ClaimServiceEndDate\"]+delta\n",
    "    delta = pd.to_timedelta(np.random.randint(0,3, size=len(final_df)), unit='d')\n",
    "    final_df[\"ClaimPaidDate\"] = final_df[\"ClaimReceivedDate\"] +delta\n",
    "    #remove accident date for all but 2% of claims to mimick real data. \n",
    "    #Probably should eventually be based on hcpcs and mod but not now.\n",
    "    number_one = len(final_df) // 50    \n",
    "    final_df_date = final_df.iloc[:number_one]\n",
    "    final_df_ndate = final_df.iloc[number_one:]\n",
    "    final_df_date[\"AccidentDate\"]=final_df_date[\"AccidentDate\"].astype(str)\n",
    "    final_df_date[\"RelatedCausesCode\"] = np.random.choice([\"AA\", \"AP\",\"EM\", \"OA\"], final_df_date.shape[0],\n",
    "                                                          p=[0.2, 0.1,0.3, 0.4])\n",
    "    final_df_date[\"LineCOBPay\"] = np.random.uniform(.7,.9, size = final_df_date.shape[0])\n",
    "    \n",
    "    final_df_ndate[\"AccidentDate\"]=\"\"\n",
    "    final_df_ndate[\"LineCOBPay\"] = 0\n",
    "    final_df_date[\"RelatedCausesCode\"] =\"\"\n",
    "    return pd.concat([final_df_ndate, final_df_date])\n",
    "######################################################################################################################\n",
    "def ren_is_bill(final_df):\n",
    "    nr1_df = pd.DataFrame()\n",
    "    ren_df = final_df.loc[(final_df['bad3'] == 'N')]\n",
    "    nr_df = final_df.loc[(final_df['bad3'] == 'Y')]\n",
    "    nr1_df = final_df.loc[(final_df['super_bad'] == 'Y')]\n",
    "    nr_df = pd.concat([nr1_df, nr_df])\n",
    "    nr_df[\"BillingProviderID\"]= nr_df[\"RenderingProviderID\"]\n",
    "    nr_df[\"BillingProviderNPI\"]= nr_df[\"RenderingProviderNPI\"]\n",
    "    nr_df[\"BillingProviderTIN\"]= nr_df[\"RenderingProviderTIN\"]\n",
    "    nr_df[\"BillingProviderSpecialtyCode\"]= nr_df[\"RenderingProviderSpecialtyCode\"]\n",
    "    nr_df[\"BillingProviderTaxonomy\"]= nr_df[\"RenderingProviderTaxonomy\"]\n",
    "    nr_df[\"BillingProviderOrg\"]= nr_df[\"RenderingProviderOrg\"]\n",
    "    nr_df[\"BillingProviderFName\"]= nr_df[\"RenderingProviderFName\"]\n",
    "    nr_df[\"BillingProviderMName\"]= nr_df[\"RenderingProviderMName\"]\n",
    "    nr_df[\"BillingProviderLName\"]= nr_df[\"RenderingProviderLName\"]\n",
    "    nr_df[\"BillingProviderEntityType\"]= nr_df[\"RenderingProviderEntityType\"]\n",
    "    nr_df[\"BillingProviderAddressLine1\"]= nr_df[\"RenderingProviderAddressLine1\"]\n",
    "    nr_df[\"BillingProviderAddressLine2\"]= nr_df[\"RenderingProviderAddressLine2\"]\n",
    "    nr_df[\"BillingProviderCity\"]= nr_df[\"RenderingProviderCity\"]\n",
    "    nr_df[\"BillingProviderState\"]= nr_df[\"RenderingProviderState\"]\n",
    "    nr_df[\"BillingProviderZipCode\"]= nr_df[\"RenderingProviderZipCode\"]\n",
    "    nr_df[\"BillingProviderPhoneNumber\"] = nr_df[\"RenderingProviderPhoneNumber\"]\n",
    "    return pd.concat([ren_df, nr_df])\n",
    "######################################################################################################################\n",
    "def claim_peppering(final_df):\n",
    "    #time decrease\n",
    "    i = 0\n",
    "    j = 0\n",
    "    w = 0\n",
    "    final_df = final_df.reset_index()\n",
    "    while w < 15:\n",
    "        w+=1\n",
    "        c= final_df.shape[0] - 40\n",
    "        i = np.random.randint(10, c)\n",
    "        j = i+np.random.randint(5, 20)\n",
    "        final_df = final_df.drop(final_df.index[i:j])\n",
    "\n",
    "    \n",
    "    ##time increase\n",
    "    \n",
    "    #i = 0\n",
    "    #j = 0\n",
    "    #w = 0\n",
    "    #final_df=final_df.sort_values(by=['combos', 'AdmitDate',\"RenderingProviderNPI\"])\n",
    "    #while w < 20:\n",
    "    #    w+=1\n",
    "    #    c= final_df.shape[0] - 40\n",
    "    #    i = np.random.randint(10, c)\n",
    "    #    j = i+np.random.randint(5, 20)\n",
    "    #    split df in 2 one has range other doesn't chage date to decrease num months concat back together\n",
    "    \n",
    "    #claim duplicates\n",
    "    i = 0\n",
    "    j = 0\n",
    "    w = 0\n",
    "    final_df = final_df.reset_index()\n",
    "    \n",
    "    while w < 80:\n",
    "        w+=1\n",
    "        i = np.random.randint(50,c)\n",
    "        j = i+np.random.randint(10, 20)\n",
    "        df = final_df.sample(frac=0.01, replace=True, random_state=1)\n",
    "        final_df = pd.concat([final_df, df])\n",
    "    sb_df1= final_df.loc[(final_df['super_bad'] == 'Y')]\n",
    "    df1 = pd.DataFrame()\n",
    "    while w < 10:\n",
    "        w+=1\n",
    "        try:\n",
    "            c= sb_df1.shape[0] - 10\n",
    "            i = np.random.randint(10,c)\n",
    "            j = i+np.random.randint(10, 20)\n",
    "            df = sb_df1.sample(frac=0.01, replace=True, random_state=1)\n",
    "            df1 = pd.concat([df1, df])\n",
    "        except:\n",
    "            print(\"dupes failed for a run\")\n",
    "    return pd.concat([final_df, df1])\n",
    "######################################################################################################################\n",
    "def line_nums(final_df):\n",
    "    line_df = pd.DataFrame()\n",
    "    line_df[\"len\"] = final_df['combos'].str.len()\n",
    "    line_df['LineNumber'] = line_df.apply(lambda x: list(range(1, x.len + 1)), axis=1)\n",
    "    line_df= line_df.explode('LineNumber')\n",
    "    \n",
    "    final_df = final_df.explode('combos')#spliting up line into HCPCS and mod value in list, first is Hcpcs, \n",
    "    #second is mod for line\n",
    "    final_df[\"LineNumber\"]=line_df[\"LineNumber\"]\n",
    "    del line_df\n",
    "    final_df[\"combos\"] = final_df[\"combos\"].apply(lambda x: x.split(\";\"))\n",
    "    final_df[['hcpcs_code','ToothNumber', \"ToothBegin\", \"ToothEnd\", \"ToothSurfaces\"]] = pd.DataFrame(final_df.pop('combos').values.tolist(), index=final_df.index)\n",
    "    final_df['hcpcs_code'] = final_df['hcpcs_code'].apply(lambda x: '{0:0>5}'.format(x))\n",
    "    final_df['ren_id'] = final_df['ren_id'].astype(str)\n",
    "    final_df[\"combos\"] = final_df[\"hcpcs_code\"] +\";\"+final_df[\"ToothNumber\"] +\";\"+final_df[\"ToothBegin\"] +\";\"+final_df[\"ToothEnd\"] +\";\"+final_df[\"ToothSurfaces\"]\n",
    "    final_df[\"combos\"] =final_df[\"combos\"].fillna(\"\")\n",
    "    return final_df\n",
    "######################################################################################################################\n",
    "def def_bad_provs(final_df):\n",
    "    final_df[\"ren_id\"] = final_df[\"ren_id\"].astype(int)\n",
    "    sb_df= final_df.loc[(final_df['ren_id'] <=3)]\n",
    "    nb_df = final_df.loc[(final_df['ren_id'] > 3)]\n",
    "    sb_df[\"super_bad\"] = \"Y\"\n",
    "    sb_df[\"bad1\"] = \"N\"\n",
    "    sb_df[\"bad2\"] = \"N\"\n",
    "    nb_df[\"super_bad\"] = \"N\"\n",
    "    nb_df[\"bad1\"] = \"N\"\n",
    "    nb_df[\"bad2\"] =  \"N\"\n",
    "    nb_df[\"bad3\"] =  \"N\"\n",
    "    nb_df.iloc[75:180, nb_df.columns.get_loc('bad1')] = \"Y\"\n",
    "    nb_df.iloc[172:265, nb_df.columns.get_loc('bad2')] = \"Y\"\n",
    "    nb_df.iloc[5:75, nb_df.columns.get_loc('bad3')] = \"Y\"\n",
    "    \n",
    "    return pd.concat([sb_df, nb_df])\n",
    "######################################################################################################################\n",
    "def state_info(rendering_df, location_csv):    \n",
    "    zip_length = rendering_df.shape[0] + 10\n",
    "    \n",
    "    zip_df = pd.read_csv(location_csv)\n",
    "    zip_df['subscriberstate'] = zip_df['subscriberstate'].astype(str)\n",
    "    zip_df[\"billingproviderstate\"]=zip_df[\"billingproviderstate\"].astype(str)\n",
    "    zip_df[\"renderingproviderstate\"]=zip_df[\"renderingproviderstate\"].astype(str)\n",
    "    \n",
    "    zip_df1 = zip_df.loc[(zip_df['subscriberstate'] == \"0.0\")]\n",
    "    zip_df2 = zip_df.loc[(zip_df['subscriberstate'] != \"0.0\")]\n",
    "    zip_df1[\"subscriberstate\"] = \"GA\"\n",
    "    zip_df = pd.concat([zip_df1, zip_df2])\n",
    "    \n",
    "    zip_df1 = zip_df.loc[(zip_df['billingproviderstate'] == \"0.0\")]\n",
    "    zip_df2 = zip_df.loc[(zip_df['billingproviderstate'] != \"0.0\")]\n",
    "    zip_df1[\"billingproviderstate\"] = zip_df1[\"subscriberstate\"] \n",
    "    zip_df = pd.concat([zip_df1, zip_df2])\n",
    "    \n",
    "    zip_df1 = zip_df.loc[(zip_df['renderingproviderstate'] == \"0.0\")]\n",
    "    zip_df2 = zip_df.loc[(zip_df['renderingproviderstate'] != \"0.0\")]\n",
    "    zip_df1[\"renderingproviderstate\"] = zip_df1[\"billingproviderstate\"] \n",
    "    zip_df = pd.concat([zip_df1, zip_df2])\n",
    "    \n",
    "    zip_df[\"prob_combo\"] = zip_df[\"prob_combo\"].astype(float)\n",
    "    zip_df[\"prob_combo\"] = 3*zip_df[\"prob_combo\"]*zip_df[\"prob_combo\"]\n",
    "    \n",
    "    return zip_df.set_index(['billingproviderstate', 'renderingproviderstate',\n",
    "                             'subscriberstate', 'prob_combo']).astype('float64').astype('int64').reset_index()\n",
    "    \n",
    "######################################################################################################################\n",
    "def zip_info(dfRendChoices):\n",
    "    dfRendChoices['subscriberzipcode'] = dfRendChoices['subscriberzipcode'].astype(str)\n",
    "    dfRendChoices['renderingproviderzipcode'] =dfRendChoices['renderingproviderzipcode'].astype(str)\n",
    "    dfRendChoices['patientzipcode']=dfRendChoices['patientzipcode'].astype(str)\n",
    "    dfRendChoices['billingproviderzipcode']=dfRendChoices['billingproviderzipcode'].astype(str)\n",
    "    \n",
    "    dfRendChoices['SubscriberCity'] = dfRendChoices['subscriberzipcode'].str[:5]\n",
    "    dfRendChoices['RenderingProviderCity'] = dfRendChoices['renderingproviderzipcode'].str[:5]\n",
    "    dfRendChoices['PatientCity'] = dfRendChoices['patientzipcode'].str[:5]\n",
    "    dfRendChoices['BillingProviderCity'] = dfRendChoices['billingproviderzipcode'].str[:5]\n",
    "    \n",
    "    dfRendChoices['BillingProviderCity'] = dfRendChoices['BillingProviderCity'].str.replace('.','')\n",
    "    dfRendChoices['PatientCity'] = dfRendChoices['PatientCity'].str.replace('.','')\n",
    "    dfRendChoices['SubscriberCity'] =dfRendChoices['SubscriberCity'].str.replace('.','')\n",
    "    dfRendChoices['RenderingProviderCity'] = dfRendChoices['RenderingProviderCity'].str.replace('.','')\n",
    "    \n",
    "    dfRendChoices['BillingProviderCity'] = dfRendChoices['BillingProviderCity'].astype(float)\n",
    "    dfRendChoices['PatientCity'] = dfRendChoices['PatientCity'].astype(float)\n",
    "    dfRendChoices['SubscriberCity'] = dfRendChoices['SubscriberCity'].astype(float)\n",
    "    dfRendChoices['RenderingProviderCity'] = dfRendChoices['RenderingProviderCity'].astype(float)\n",
    "    \n",
    "    dfRendChoices['SubscriberCity'] = dfRendChoices['SubscriberCity'].fillna(0).astype(int).apply(zcode)\n",
    "    dfRendChoices['RenderingProviderCity'] = dfRendChoices['RenderingProviderCity'].fillna(0).astype(int).apply(zcode)\n",
    "    dfRendChoices['PatientCity'] = dfRendChoices['PatientCity'].fillna(0).astype(int).apply(zcode)\n",
    "    dfRendChoices['BillingProviderCity'] = dfRendChoices['BillingProviderCity'].fillna(0).astype(int).apply(zcode)\n",
    "    dfRendChoices.rename(columns = {'billingproviderzipcode':'BillingProviderZipCode',\n",
    "                                    \"renderingproviderzipcode\": \"RenderingProviderZipCode\",\n",
    "                                    \"pickupzipcode\":\"PickUpZipCode\", \"dropoffzipcode\":\"DropOffZipCode\",\n",
    "                                    \"prescribingproviderzipcode\":\"PrescribingProviderZipCode\",\n",
    "                                    \"subscriberzipcode\":\"SubscriberZipCode\", \"patientzipcode\":\"PatientZipCode\",\n",
    "                                    \"billingproviderstate\":\"BillingProviderState\",\n",
    "                                    'renderingproviderstate':\"RenderingProviderState\",\n",
    "                                    'subscriberstate':\"SubscriberState\" }, inplace = True)\n",
    "    return dfRendChoices\n",
    "######################################################################################################################\n",
    "def payments(final_df, c_amt_csv, d_amt_csv):\n",
    "    c = pd.read_csv(c_amt_csv)\n",
    "    d = pd.read_csv(d_amt_csv)\n",
    "    c = c.fillna(0)\n",
    "    d = d.fillna(0)\n",
    "    final_df['combo'] = final_df['combo'].astype(str)\n",
    "    final_df['combo'] = final_df[\"combo\"].apply(lambda x: x.split(\"@\"))\n",
    "    final_df['combo'] = final_df['combo'].apply(sorted)\n",
    "    final_df['combo'] = final_df['combo'].transform(lambda x: '@'.join(x))\n",
    "    \n",
    "    scb = 50      #may want to change scale so that it is more in line with reality\n",
    "    sca = .05\n",
    "    cost_dict = c.set_index('combo').to_dict()\n",
    "    \n",
    "    final_df['combo'] = final_df['combo'].fillna(0)\n",
    "    final_df['combo'] = final_df['combo'].astype(str)\n",
    "    final_df = final_df.loc[(final_df['combo'] != \"nan\")]\n",
    "    \n",
    "    t1_df= pd.read_csv(c_amt_csv)\n",
    "    t2_df= pd.read_csv(d_amt_csv)\n",
    "    \n",
    "    t1_lst = t1_df['combo'].tolist()\n",
    "    t2_lst = t2_df['combo'].tolist()\n",
    "    t3_lst = t1_lst and t2_lst\n",
    "    final_df[\"combo\"] = final_df[\"combo\"].astype(str)\n",
    "    comb_lst = final_df[\"combo\"].tolist()\n",
    "    #final_df[\"combo\"] = final_df[\"combo\"].apply(lambda x: x.split(\":\"))\n",
    "    safe = []\n",
    "    for a in comb_lst:\n",
    "        if a in t3_lst:\n",
    "            safe.append(\"T\")\n",
    "        else:\n",
    "            safe.append(\"F\")\n",
    "    final_df[\"safe\"] = safe\n",
    "    \n",
    "    final_df =  final_df.loc[(final_df['safe'] == \"T\")]\n",
    "    \n",
    "    final_df['cost'] = final_df['combo'].apply(lambda x: cost_dict[\"avg_charge\"][x])\n",
    "    final_df['real_charge'] = np.random.normal(final_df['cost'], scale = scb,\n",
    "                                               size = final_df.shape[0]).astype(int)\n",
    "    final_df['real_charge'] = final_df['real_charge'].abs()\n",
    "    final_df = final_df.drop(columns=['cost', \"bad1\", \"bad2\"])\n",
    "    paid_dict = d.set_index('combo').to_dict()\n",
    "    final_df['paid'] = final_df['combo'].apply(lambda x: paid_dict[\"avg_paid_pct\"][x])\n",
    "    \n",
    "    \n",
    "    final_df['real paid'] = np.random.normal(final_df['paid'], scale = sca,\n",
    "                                             size = final_df.shape[0])*final_df[\"real_charge\"].astype(int)\n",
    "    final_df['real paid'] = final_df['real paid'].abs()\n",
    "    \n",
    "    final_df = final_df.drop(columns=['paid'])\n",
    "    final_df[\"real paid\"] = final_df[\"real paid\"].astype('int64', copy=False, errors='ignore')\n",
    "    final_df[\"claim\"] = final_df[\"ClaimID\"]+\"@\"+final_df[\"ren_id\"]\n",
    "    \n",
    "    final_df_1 = final_df\n",
    "    final_df_1.groupby(['claim']).agg({'real_charge': sum, 'real paid': sum}).reset_index()\n",
    "    \n",
    "    final_df[\"total charged\"] = final_df_1[\"real_charge\"]\n",
    "    final_df[\"total paid\"] = final_df_1[\"real paid\"]*1.4\n",
    "    final_df = final_df.drop(columns=['claim'])\n",
    "    final_df = final_df.rename(columns = {'pat_gender':'PatientGender', \"place_of_service\": \"LinePOS\",\n",
    "                                          \"total paid\":\"LineTotPaid\", \"total charged\":\"LineCharges\",\n",
    "                                          \"hcpcs_code\":\"LineProcCode\"})\n",
    "        \n",
    "    final_df[\"LineTotPaid\"] = final_df[\"LineTotPaid\"].astype('int64', copy=False, errors='ignore')  \n",
    "    \n",
    "    final_df[\"LineCOBPay\"] = final_df[\"LineCOBPay\"]*final_df[\"LineTotPaid\"]\n",
    "    \n",
    "    par_df = final_df.loc[(final_df['ContractedFlag'] == 'Subscriber')]\n",
    "    np_df = final_df.loc[(final_df['ContractedFlag'] != 'Subscriber')]\n",
    "    np_df[\"LineAmountCoinsurance\"] = np.random.randint(20,50, size=final_df.shape[0])/100\n",
    "    par_df[\"LineAmountCoinsurance\"] = 0\n",
    "    final_df = pd.concat([par_df, np_df])\n",
    "    #print(final_df)\n",
    "    final_df[\"LineAmountCoinsurance\"] = np.random.randint(0,10, size=final_df.shape[0])/100\n",
    "    final_df[\"LineAmountDeductible\"]= np.random.randint(0,20, size=final_df.shape[0])/100\n",
    "    final_df[\"LineAmountCopay\"]=[random.randrange(5,26,5)for i in range(final_df.shape[0])]\n",
    "    final_df[\"LinePayerPaid\"]=final_df[\"LineTotPaid\"]-final_df[\"LineAmountCopay\"]\n",
    "    final_df[\"LineAmountCoinsurance\"] = final_df[\"LineAmountCoinsurance\"] * final_df[\"LinePayerPaid\"]//1\n",
    "    final_df[\"LinePayerPaid\"]=final_df[\"LineTotPaid\"]-final_df[\"LineAmountCopay\"]- final_df[\"LineAmountCoinsurance\"]\n",
    "    final_df['LinePayerPaid'] = final_df['LinePayerPaid'].abs()\n",
    "    final_df[\"LineAmountDeductible\"] = final_df[\"LineAmountDeductible\"] * final_df[\"LinePayerPaid\"]//1\n",
    "    #function definitions for when the claim might not get paid, ie plastic surgery or otherwise rejected.\n",
    "    \n",
    "    def nopay(x):\n",
    "        if x[\"LineProcCode\"] in nopay_dict.keys():\n",
    "            if random.randrange(100) < nopay_dict[x[\"LineProcCode\"]]*100:\n",
    "                return 0\n",
    "        return x[\"LinePayerPaid\"]\n",
    "    def nopay2(x):\n",
    "        if x[\"LineProcCode\"] in nopay_dict.keys():\n",
    "            if random.randrange(100) < nopay_dict[x[\"LineProcCode\"]]*100:\n",
    "                return  np.random.choice([ \"Rejected\", \"Additional Information Requested\"], p=[0.7, 0.3,])\n",
    "        return \"Accepted\"\n",
    "    def nopay3(x):\n",
    "        if x[\"LineProcCode\"] in nopay_dict.keys():\n",
    "                if random.randrange(100) < nopay_dict[x[\"LineProcCode\"]]*100:\n",
    "                    return  \"Subsciber\"\n",
    "        return \"Prov\"\n",
    "    def nopay4(x):\n",
    "        if x[\"ContractedFlag\"] == \"NONPAR\":\n",
    "            return  \"Subscriber\"\n",
    "        return x[\"PayeeType\"]\n",
    "    final_df[\"LinePayerPaid\"] = final_df.apply(nopay, axis=1)\n",
    "    #final_df[\"LineServiceStatusCategoryCode\"] = final_df.apply(nopay2, axis=1)\n",
    "    final_df[\"PayeeType\"] = final_df.apply(nopay3, axis=1)\n",
    "    final_df[\"PayeeType\"] = final_df.apply(nopay4, axis=1)\n",
    "    final_df[\"SubscriberState\"]= final_df[\"PatientState\"]\n",
    "    final_df['LineAmountCoinsurance'] = final_df['LineAmountCoinsurance'].abs()\n",
    "    final_df['LineAmountDeductible'] = final_df['LineAmountDeductible'].abs()\n",
    "    final_df[\"LinePatientPaid\"] = final_df[\"LineAmountCopay\"] + final_df[\"LineAmountDeductible\"] + final_df[\"LineAmountCoinsurance\"]\n",
    "    final_df[\"LineTotPaid\"] = final_df[\"LinePatientPaid\"]+final_df[\"LineCOBPay\"]+ final_df[\"LinePayerPaid\"]\n",
    "    \n",
    "    print(final_df.shape[0])\n",
    "    final_df = final_df.loc[(final_df['LineTotPaid'] <= 1000000)]\n",
    "    return final_df\n",
    "######################################################################################################################\n",
    "def save_files(final_df, folder, taxonomy):\n",
    "    rend_file=pd.DataFrame()\n",
    "    rend_file[\"etl_provider_key\"]=\"\"\n",
    "    rend_file[\"ProviderNPI\"]=final_df[\"RenderingProviderNPI\"] \n",
    "    rend_file[\"predicted_specialty_id_1\"] = taxonomy\n",
    "    rend_file[\"number_of_predicted_specialties\"]=\"1\"\n",
    "    rend_file[\"specialty_1_probability_value\"]=\"\"\n",
    "    rend_file[\"predicted_specialty_id_2\"]=\"\"\n",
    "    rend_file[\"specialty_2_probability_value\"]=\"\"\n",
    "    rend_file[\"predicted_specialty_id_3\"]=\"\"\n",
    "    rend_file[\"specialty_3_probability_value\"]=\"\"\n",
    "    rend_file[\"customer_provided_specialty_desc\"]=\"\"\n",
    "    rend_file[\"npi_reg_primary_taxonomy_code\"]=\"\"\n",
    "    rend_file[\"used_cust_specialty_flg\"]=\"\"\n",
    "    rend_file = rend_file.drop_duplicates(subset = ['ProviderNPI'],keep = 'last').reset_index(drop = True)\n",
    "\n",
    "    bill_prov_file=pd.DataFrame()\n",
    "    bill_prov_file['etl_provider_key'] = ''\n",
    "    bill_prov_file['ProviderNPI'] = final_df['BillingProviderNPI']\n",
    "    bill_prov_file['predicted_specialty_id_1'] = final_df['BillingProviderSpecialtyCode']\n",
    "    bill_prov_file['number_of_predicted_specialties'] = '1'\n",
    "    bill_prov_file['specialty_1_probability_value'] = ''\n",
    "    bill_prov_file['predicted_specialty_id_2'] = ''\n",
    "    bill_prov_file['specialty_2_probability_value'] = ''\n",
    "    bill_prov_file['predicted_specialty_id_3'] = ''\n",
    "    bill_prov_file['specialty_3_probability_value'] = ''\n",
    "    bill_prov_file['customer_provided_specialty_desc'] = ''\n",
    "    bill_prov_file['npi_reg_primary_taxonomy_code'] = ''\n",
    "    bill_prov_file['used_cust_specialty_flg'] = ''\n",
    "    bill_prov_file[\"cust_claim_specialty_desc\"]=\"\"\n",
    "    bill_prov_file[\"cdx_claim_id\"]=\"\"\n",
    "    bill_prov_file[\"claim_specialty_id\"]=\"\"\n",
    "    bill_prov_file[\"claim_specialty_probability_value\"]=\"\"\n",
    "    bill_prov_file = bill_prov_file.drop_duplicates(subset = ['ProviderNPI'],keep = 'last').reset_index(drop = True)\n",
    "\n",
    "    rend_file.to_csv(\"Out/Dental/\"+folder+\"_provider_file1.csv\", index=False)\n",
    "    bill_prov_file.to_csv(\"Out/Dental/\"+folder+\"_provider_file2.csv\", index=False)\n",
    "    final_df = final_df.sample(frac=1)\n",
    "    final_df = final_df.sort_values(by=['ClaimID'])\n",
    "    final_df = final_df.sort_values(by=['ClaimPaidDate'])\n",
    "\n",
    "    final_df[\"Date\"] = final_df[\"ClaimPaidDate\"]\n",
    "    final_df[\"Date\"] = final_df[\"Date\"].astype(str)\n",
    "    final_df[\"Date\"] = final_df[\"Date\"].str[:7]\n",
    " \n",
    "    final_df = final_df.drop_duplicates(subset = ['ClaimID', 'LineNumber'],keep = 'last').reset_index(drop = True)\n",
    "    #save data to sagemaker based on month of claim\n",
    "    \n",
    "    out = final_df\n",
    "    out = out.drop(columns=['Date'])\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    c = \"\"\n",
    "    for index, row in final_df.iterrows():\n",
    "        j+=1\n",
    "        if not (c ==row[\"Date\"]):\n",
    "            c = row[\"Date\"]\n",
    "            if k!=0:\n",
    "                strBucket = 'data-science-synthdata-dev'\n",
    "                strTestFile = \"Out/Dental/\"+str(i)+\"/\"+folder+\"_Month_\"+str(i)+'.csv'\n",
    "                out.iloc[k:j-1].to_csv(strTestFile, index=False)\n",
    "            k = j\n",
    "            i+=1\n",
    "    final_df.to_csv(\"Out/Dental/\"+str(folder)+\".csv\",  index=False)#sep=\"|\",\n",
    "\n",
    "######################################################################################################################\n",
    "def bill_prov_null_zip(final_df):\n",
    "    nz_df= final_df.loc[(final_df['BillingProviderZipCode'] == \"\")]\n",
    "    z_df=final_df.loc[(final_df['BillingProviderZipCode'] != \"\")]\n",
    "    nz_df[\"BillingProviderAddressLine1\"] =\"\"\n",
    "    nz_df[\"BillingProviderAddressLine2\"] =\"\" \n",
    "    return pd.concat([nz_df, z_df])\n",
    "######################################################################################################################\n",
    "def pat_relationship(final_df):\n",
    "    pa_df = final_df.loc[(final_df['PatientRelationship'] != 'Subscriber')]\n",
    "    su_df = final_df.loc[(final_df['PatientRelationship'] == 'Subscriber')]\n",
    "    su_df['PatientID'] = su_df[\"SubscriberID\"]\n",
    "    return pd.concat([pa_df, su_df]) \n",
    "######################################################################################################################\n",
    "def group_info(num_providers):\n",
    "    group_df = pd.DataFrame()\n",
    "    group_df['GroupName'] = [fake.company() for i in range(num_providers)]\n",
    "    group_df['GroupNumber']  = np.random.randint(10000,999999, size=num_providers)\n",
    "    group_df['GroupNumber'] = group_df['GroupNumber'].astype(str)\n",
    "    group_df[\"Group\"] = group_df['GroupName']+\"@\"+group_df['GroupNumber']\n",
    "    return group_df[\"Group\"].tolist()\n",
    "######################################################################################################################\n",
    "def insurance_type(final_df):\n",
    "    e_df = final_df.loc[(final_df['age_bin'] == 'Elderly')]\n",
    "    n_df = final_df.loc[(final_df['age_bin'] != 'Elderly')]    \n",
    "    e_df[\"LineOfBusiness\"] = np.random.choice([\"Medicare\", \"Commercial Plus\"],  e_df.shape[0], p=[0.95, 0.05])\n",
    "    n_df[\"LineOfBusiness\"] = np.random.choice([\"Commercial\", \"Medicare\", \"Commercial Plus\"], n_df.shape[0],\n",
    "                                              p=[0.5, 0.05, 0.45])\n",
    "    return pd.concat([n_df, e_df])    \n",
    "######################################################################################################################\n",
    "def hdr_pay(final_df):\n",
    "    final_df[\"HdrCOBPay\"] = \"0\"\n",
    "    final_df = final_df.sort_index(ascending=True)\n",
    "    \n",
    "    hdr_df= final_df[[\"ClaimID\",\"LineTotPaid\", \"LineAmountCopay\", \"LinePayerPaid\",  \"LineCharges\",\"LinePatientPaid\" ]]\n",
    "    \n",
    "    hdr_df = hdr_df.groupby(['ClaimID'], as_index=False).agg({'LineTotPaid': 'sum','LinePatientPaid': 'sum',\n",
    "                                                              'LineAmountCopay': 'sum','LinePayerPaid': 'sum','LineCharges': 'sum'})\n",
    "    hdr_df.rename(columns={'LineTotPaid':'HdrPay','LinePayerPaid': 'HdrPayerPay',\n",
    "                           'LineAmountCopay': 'HdrPatientCopay', 'LineCharges': 'HdrCharges','LinePatientPaid': 'HdrPatientPay'}, inplace=True)\n",
    "    final_df = pd.merge(final_df, hdr_df, on='ClaimID')\n",
    "    \n",
    "    def amtChg(x):\n",
    "        return max(x['LineCharges'], x['LineTotPaid'])\n",
    "    print('LinePatientPaid')\n",
    "    final_df['LinePatientPaid'] = (final_df['LineAmountCoinsurance'].astype(float)\n",
    "                                + final_df['LineAmountDeductible'].astype(float) \n",
    "                                + final_df['LineAmountCopay'].astype(float))\n",
    "    print('LineTotPaid')\n",
    "    final_df['LineTotPaid'] = (final_df['LinePatientPaid'].astype(float)\n",
    "                            + final_df['LinePayerPaid'].astype(float) \n",
    "                            + final_df['LineCOBPay'].astype(float))\n",
    "    print('LinCharges')\n",
    "    final_df['LineCharges'] = final_df.apply(amtChg,axis = 1)\n",
    "    print('HDR')\n",
    "    dfHdr = final_df.groupby(['ClaimID'],as_index = False).agg({'LineCOBPay' : 'sum', \n",
    "                                                          'LinePayerPaid' : 'sum', \n",
    "                                                          'LineCharges' : 'sum'})\n",
    "    \n",
    "    dfHdr.columns = ['ClaimID', 'HdrCOBPay', 'HdrPayerPay', 'HdrCharges']\n",
    "    \n",
    "    final_df = final_df.drop(columns = dfHdr.columns[1:]).merge(dfHdr, on = 'ClaimID')\n",
    "    return final_df\n",
    "######################################################################################################################\n",
    "def bill_info(num_providers, taxonomy, bill_lst):\n",
    "    billing_df = pd.DataFrame()\n",
    "    billing_df['BillingProviderTaxonomy'] = np.random.choice(tax[taxonomy], num_providers//6)\n",
    "    billing_df[\"bill\"] = np.random.choice(bill_lst, billing_df.shape[0])\n",
    "    billing_df[\"Billing\"] = billing_df[\"bill\"] +\"@\"+ billing_df['BillingProviderTaxonomy']\n",
    "    return billing_df[\"Billing\"].tolist()\n",
    "\n",
    "######################################################################################################################\n",
    "def tooth_order(final_df):\n",
    "    #final_df[\"ToothBegin\"] = final_df[\"ToothBegin\"].astype(int)\n",
    "    #final_df[\"ToothEnd\"] = final_df[\"ToothEnd\"].astype(int)\n",
    "    final_df[\"1\"] = final_df[[\"ToothBegin\", \"ToothEnd\"]].values.tolist()\n",
    "    th_lst = final_df[\"1\"].tolist()\n",
    "    b = []\n",
    "    for a in th_lst:\n",
    "        a.sort()\n",
    "        b.append(a)\n",
    "    final_df[\"1\"] = b\n",
    "    final_df= final_df.drop(columns=['ToothBegin', \"ToothEnd\"])\n",
    "    final_df[['ToothBegin','ToothEnd']] = pd.DataFrame(final_df.pop('1').values.tolist(), index=final_df.index)\n",
    "    return final_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05a2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tax = pd.read_csv(\"Input/Professional/specialties_table.csv\")\n",
    "\n",
    "df_tax['id|specialty|taxonomy_codes'] = df_tax['id|specialty|taxonomy_codes'].str.split('|')\n",
    "\n",
    "\n",
    "\n",
    "df_tax['id|specialty|taxonomy_codes'] = df_tax['id|specialty|taxonomy_codes'].apply(getLastValue)\n",
    "df_tax['id|specialty|taxonomy_codes'] = df_tax['id|specialty|taxonomy_codes'].str.split('@')\n",
    "\n",
    "tax = df_tax.set_index('0')['id|specialty|taxonomy_codes'].to_dict()\n",
    "tax_ls = tax.values()\n",
    "tax_lst = [item for sublist in tax_ls for item in sublist]\n",
    "\n",
    "df_preauth = pd.read_csv(\"Input/Professional/preauth.csv\")\n",
    "df_preauth= df_preauth.sort_values(by=['percent'], ascending=False)\n",
    "df_preauth['percent'] = df_preauth['percent'].astype(float)\n",
    "df_preauth = df_preauth.drop(columns=[\"Unnamed: 0\"])\n",
    "preauth_dict = dict(df_preauth.values)\n",
    "\n",
    "nopay_df = pd.read_csv(\"Input/Professional/hdrpatpay.csv\")\n",
    "nopay_df = nopay_df.sort_values(by=['percent'], ascending=False)\n",
    "nopay_df = nopay_df.drop(columns=[\"Unnamed: 0\"])\n",
    "nopay_dict = dict(nopay_df.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e36c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_num = 0\n",
    "\n",
    "def syn_data(taxonomy,  folder, div):\n",
    "#taxonomy =6\n",
    "#folder =\"Anesthesiology\"\n",
    "#div = 1\n",
    "    num_claims_csv =\"Input/Dental/\"+ folder+\"/num_claim_df.csv\"\n",
    "    all_combo_csv = \"Input/Dental/\"+ folder+\"/all_combinations_age.csv\"\n",
    "    location_csv = \"Input/Dental/\"+ folder+\"/location_data.csv\"\n",
    "    c_amt_csv = \"Input/Dental/\"+ folder+\"/c.csv\"\n",
    "    d_amt_csv =\"Input/Dental/\"+  folder+\"/d.csv\"\n",
    "    srvs_csv = \"Input/Dental/\"+  folder+\"/srvc_cnts.csv\"\n",
    "    \n",
    "    def splitting(name, delineator = \"@\"):\n",
    "        final_df[name] = final_df[name].apply(lambda x: x.split(delineator))\n",
    "        \n",
    "    def preauth(x):\n",
    "            if x in preauth_dict.keys():\n",
    "                if random.randrange(100) <= preauth_dict[x]*100:\n",
    "                    return \"Y\"\n",
    "            return \"N\"\n",
    "        \n",
    "    def splitting3(col_name, num):\n",
    "        col_name = col_name.split('@')\n",
    "        null_vals = num - len(col_name)\n",
    "        null_lst = [\"\"] * null_vals\n",
    "        col_name = col_name + null_lst\n",
    "        return col_name     \n",
    "    \n",
    "    a = \"dent_\"+folder.lower()\n",
    "    ren_df = pd.read_csv(\"Input/rendering_prov.csv\")\n",
    "    ren_df= ren_df[ren_df[\"Tax\"].str.contains(a)]\n",
    "    ren_lst = ren_df[\"REN\"].tolist()\n",
    "    ren_df = pd.read_csv(\"Input/billing_prov.csv\")\n",
    "    \n",
    "    ren_df= ren_df[ren_df[\"Tax\"].str.contains(a)] \n",
    "    bill_lst = ren_df[\"BILL\"].tolist()\n",
    "    \n",
    "    rendering_df = pd.DataFrame()\n",
    "    num_claims_df = pd.read_csv(num_claims_csv)\n",
    "    num_providers = int(num_claims_df.shape[0]*(div))#may want to edit this, going lower than \n",
    "    #about 10 requires more RAM\n",
    "    \n",
    "    rendering_df[\"RenderingProviderEntityType\"] = np.random.choice([\"I\", \"O\"], num_providers, p=[0.9, 0.1])\n",
    "    rendering_df['RenderingProviderPhoneNumber'] = [fake.msisdn() for i in range(num_providers)]\n",
    "    rendering_df['RenderingProviderTIN']= np.random.randint(100000000,999999999, size=num_providers)\n",
    "    rendering_df[\"RenderingProviderID\"] = np.random.randint(10000,999999, size=num_providers)\n",
    "    rendering_df[\"RenderingProviderID\"] = rendering_df[\"RenderingProviderID\"].astype(str)\n",
    "    rendering_df[\"ContractedFlag\"] = np.random.choice(['PAR','NONPAR'], num_providers, p=[0.8, 0.2])\n",
    "    rendering_df[\"OutOfNetwork\"]  = rendering_df[\"ContractedFlag\"].apply(lambda x: in_network(x))\n",
    "    rendering_df['1'] = [fake.building_number() for i in range(num_providers)]\n",
    "    rendering_df[\"2\"] = [fake.street_name() for i in range(num_providers)]\n",
    "    rendering_df['RenderingProviderAddressLine1'] = rendering_df[\"1\"]+\" \"+rendering_df[\"2\"]\n",
    "    rendering_df[\"1\"] = np.random.choice([\"Suite\", \"Apt.\", \"Null\"], num_providers, p=[0.05, 0.15, 0.8])\n",
    "    rendering_df[\"2\"] = [fake.building_number() for i in range(num_providers)]\n",
    "    rendering_df[\"RenderingProviderAddressLine2\"] = rendering_df[\"1\"]+\" \"+rendering_df[\"2\"]\n",
    "    rendering_df.loc[rendering_df['RenderingProviderAddressLine2'].str.contains('Null', case=False), \n",
    "                     'RenderingProviderAddressLine2'] = ''\n",
    "    \n",
    "    org1_df = rendering_df.loc[(rendering_df['RenderingProviderEntityType'] == 'O')]\n",
    "    ind1_df = rendering_df.loc[(rendering_df['RenderingProviderEntityType'] == 'I')]\n",
    "    ind1_df['RenderingProviderOrg'] = \"\"\n",
    "    ind1_df['RenderingProviderFName'] = [fake.first_name() for i in range(ind1_df.shape[0])]\n",
    "    ind1_df['RenderingProviderMName'] = [fake.first_name() for i in range(ind1_df.shape[0])]\n",
    "    ind1_df['RenderingProviderLName'] = [fake.last_name() for i in range(ind1_df.shape[0])]\n",
    "    \n",
    "    org1_df['RenderingProviderOrg'] = np.random.choice(org_lst, size=org1_df.shape[0])\n",
    "    org1_df['RenderingProviderFName'] =\"\"\n",
    "    org1_df['RenderingProviderMName'] =\"\"\n",
    "    org1_df['RenderingProviderLName'] =\"\"\n",
    "    rendering_df= pd.concat([org1_df, ind1_df])\n",
    "    \n",
    "    rendering_df['RenderingProviderPhoneNumber'] = rendering_df['RenderingProviderPhoneNumber'].astype(str)\n",
    "    rendering_df['RenderingProviderTIN'] = rendering_df['RenderingProviderTIN'].astype(str)\n",
    "    rendering_df[\"CCN\"] =\"\"\n",
    "    \n",
    "    rendering_df[\"RenderingProviderNPI\"] = np.random.randint(1000000000, 9999999999, size=num_providers)\n",
    "    rendering_df[\"RenderingProviderNPI\"] = rendering_df[\"RenderingProviderNPI\"].astype(str)\n",
    "    rendering_df['ren_id'] = range(1, 1+len(rendering_df))\n",
    "    rendering_df[\"random\"] = np.random.choice(['Y','N'], num_providers, p=[0.99, 0.01])\n",
    "    \n",
    "    tax1_df = rendering_df.loc[(rendering_df['random'] == 'Y')]\n",
    "    tax2_df = rendering_df.loc[(rendering_df['random'] == 'N')]\n",
    "    tax1_df['RenderingProviderTaxonomy'] = np.random.choice(tax[taxonomy], tax1_df.shape[0])\n",
    "    tax2_df[\"RenderingProviderTaxonomy\"] = np.random.choice(tax_lst, tax2_df.shape[0])\n",
    "    \n",
    "    rendering_df= pd.concat([tax1_df, tax2_df])\n",
    "    rendering_df = rendering_df.drop(columns=['1',\"2\", \"random\"])\n",
    "\n",
    "    #Probability of number of claims per provider\n",
    "    #We'll eventually bring inference (of number of claims for each provider) from all customers for each specialty.\n",
    "    #Based on MonteCarlo simulation from the empirical data\n",
    "\n",
    "    #How many providers do we want to synthesize?\n",
    "    ## User defined for each specialty\n",
    "    num_iter = 100000\n",
    "    num_claims_avg_lst = []\n",
    "\n",
    "    arr_claims = num_claims_df.num_claims.values\n",
    "    n_C = round(0.1*len(num_claims_df))\n",
    "    for ii in range(0, num_iter):\n",
    "        num_claims_avg_lst.append(round(arr_claims[np.random.choice(arr_claims.shape[0], n_C)].mean()))\n",
    "    \n",
    "    dist_mean = np.round(np.mean(num_claims_avg_lst))\n",
    "    dist_std = np.round(np.std(num_claims_avg_lst))\n",
    "    group = [int(round(x)) for x in np.random.normal(loc=dist_mean, scale=3*dist_std,size=num_providers)]\n",
    "    group = [int(x * 1.3) for x in group]\n",
    "    i = 0\n",
    "    while i < len(group)//5:\n",
    "        group[i]=group[i]*np.random.randint(20,50)\n",
    "        i+=1\n",
    "    group[0] = int(group[0]*2)\n",
    "    group[1] = int(group[1]*2)\n",
    "    group[2] = int(group[2]*2)\n",
    "    group = [abs(x) for x in group]\n",
    "    \n",
    "    ### Determine probability of different combinations \n",
    "    ### We'll eventually bring inference (of number of claims for each combination) from \n",
    "    #all customers for each specialty.\n",
    "    all_combinations = pd.read_csv(all_combo_csv)\n",
    "    all_combinations = all_combinations.drop(columns=[\"diag_values\"])\n",
    "    all_combinations[\"prob_claims\"] =all_combinations[\"prob_claims\"].astype(float)\n",
    "    all_combinations[\"prob_claims\"] = all_combinations[\"prob_claims\"] * all_combinations[\"prob_claims\"]\n",
    "\n",
    "    all_combinations = all_combinations.groupby(['combos', 'pat_gender', 'age_bin'],\n",
    "                                                as_index=False).agg({'num_claims': 'sum'})\n",
    "    all_combinations['prob_claims'] = all_combinations['num_claims'] / all_combinations['num_claims'].sum()\n",
    "\n",
    "    t1_df= pd.read_csv(c_amt_csv)\n",
    "    t2_df= pd.read_csv(d_amt_csv)\n",
    "    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    t1_df['combo1'] = t1_df['combo'].apply(lambda x: x.split('@'))\n",
    "    t1_df['combo2'] = t1_df.apply(lambda x: sorted(x['combo1'], key = len, reverse = True), axis = 1)\n",
    "    t1_df['combo'] = t1_df['combo2'].apply(lambda x: '@'.join(x))\n",
    "    t2_df['combo1'] = t2_df['combo'].apply(lambda x: x.split('@'))\n",
    "    t2_df['combo2'] = t2_df.apply(lambda x: sorted(x['combo1'], key = len, reverse = True), axis = 1)\n",
    "    t2_df['combo'] = t2_df['combo2'].apply(lambda x: '@'.join(x))\n",
    "    \n",
    "    t1_lst = t1_df['combo'].tolist()\n",
    "    t2_lst = t2_df['combo'].tolist()\n",
    "    t3_lst = t1_lst and t2_lst\n",
    "    \n",
    "    all_combinations[\"combos1\"] = all_combinations[\"combos\"].apply(lambda x: x.split(\":\"))\n",
    "    \n",
    "    all_combinations['combos1'] = all_combinations['combos'].str.replace(';', '@')\n",
    "    all_combinations[\"combos1\"] = all_combinations[\"combos1\"].apply(lambda x: x.split(\":\"))\n",
    "    \n",
    "    all_combinations['test1'] = all_combinations['combos1'].apply(lambda x: Counter(x))\n",
    "    test2 = Counter(t3_lst)\n",
    "    \n",
    "    all_combinations['safe'] = all_combinations['test1'].apply(\n",
    "        lambda x: True if sum(x.values()) == sum((x & test2).values()) else False)    \n",
    "\n",
    "    \n",
    "    sel_combinations =all_combinations.drop(columns=[\"combos1\",\"safe\"])\n",
    "    ## Unique combinations and corresponding weights\n",
    "    comb_list = sel_combinations.drop(['num_claims', 'prob_claims'], axis = 1).values\n",
    "    \n",
    "    weights = sel_combinations['prob_claims'].tolist()\n",
    "    \n",
    "    sel_columns= sel_combinations.drop(['num_claims', 'prob_claims'], axis = 1).columns\n",
    "    print(num_providers)\n",
    "    cdf = [weights[0]]\n",
    "    for w in weights[1:]:\n",
    "        cdf.append(cdf[-1]+w)\n",
    "\n",
    "    final_df_list = []\n",
    "    random_outliers = random.sample(range(0, num_providers), int(round(0.003*num_providers)))\n",
    "    random_outliers.append(0)\n",
    "    random_outliers.append(1)\n",
    "    random_outliers.append(2)\n",
    "    print(random_outliers)\n",
    "    for ii in range(0, num_providers):\n",
    "        if ii in random_outliers:\n",
    "            tmp = pd.DataFrame(random.choices(comb_list, k=group[ii]), \n",
    "                           columns = sel_columns)\n",
    "        else:\n",
    "            tmp = pd.DataFrame(random.choices(comb_list, cum_weights = cdf, k=group[ii]), \n",
    "                           columns = sel_columns)\n",
    "        tmp['ren_id'] = str(ii+1)\n",
    "        final_df_list.append(tmp)\n",
    "    dfFinalCombos = pd.DataFrame()\n",
    "    \n",
    "    def add_diag_values(pobjCombList, pobjWeights, pintLen):\n",
    "        objTmpOut = random.choices(pobjCombList, cum_weights = pobjWeights, k=pintLen)\n",
    "        return objTmpOut\n",
    "    \n",
    "    final_df = pd.concat(final_df_list)\n",
    "    \n",
    "    final_df = def_bad_provs(final_df)\n",
    "\n",
    "    final_df[\"combos\"] = final_df[\"combos\"].apply(lambda x: x.split(\":\"))\n",
    "    final_df['ClaimID'] = range(1, 1+len(final_df))\n",
    "    final_df['ClaimID'] = final_df['ClaimID'].astype(str)\n",
    "    final_df[\"1\"] = str(taxonomy)\n",
    "    final_df[\"1\"]=final_df[\"1\"].apply(lambda x: '{0:0>3}'.format(x))\n",
    "    final_df['ClaimID'] = \"3\"+final_df['1']+final_df['ClaimID']\n",
    "    final_df = final_df.drop(columns=['1'])\n",
    "    \n",
    "    zip_combinations = state_info(rendering_df, location_csv)\n",
    "    zip_df = zip_combinations.copy()\n",
    "    zip_length = rendering_df.shape[0] + 10\n",
    "    \n",
    "    comb_list = zip_combinations.drop(['prob_combo'], axis = 1).values\n",
    "    weights = zip_combinations['prob_combo'].tolist()\n",
    "    \n",
    "    zip_df = pd.DataFrame(random.choices(comb_list, weights, k=zip_length), columns = zip_df.drop(['prob_combo'],\n",
    "                                                                                                  axis = 1).columns)\n",
    "    rend_zips = zip_df['renderingproviderzipcode'].tolist()\n",
    "    rendering_df['renderingproviderzipcode'] = np.random.choice(rend_zips, rendering_df.shape[0])\n",
    "    \n",
    "    rend_zip_df = rendering_df.merge(zip_df.drop_duplicates(), on='renderingproviderzipcode')\n",
    "    dfRendChoices = pd.DataFrame()\n",
    "    rend_tin = rend_zip_df['RenderingProviderTIN'].unique()\n",
    "    i =0\n",
    "    for tin in rend_tin:\n",
    "        comb_list = rend_zip_df[rend_zip_df['RenderingProviderTIN'] == tin].values\n",
    "    \n",
    "        dfTmp = pd.DataFrame(random.choices(comb_list,\n",
    "                            k=random.choices([1, 2, 3,4,5], k=1)[0]), columns = rend_zip_df.columns)\n",
    "        i+=1\n",
    "        dfTmp[\"ren_id\"] = str(i)\n",
    "        dfRendChoices = dfRendChoices.append(dfTmp)\n",
    "    \n",
    "    del rend_zip_df\n",
    "    del zip_df\n",
    "    print(\"Zipping\")\n",
    "    dfRendChoices = zip_info(dfRendChoices)\n",
    "    \n",
    "    print(\"zips located\")\n",
    "    \n",
    "    rend = dfRendChoices.values.tolist()\n",
    "    out = []\n",
    "    c =[]\n",
    "    f= \"\"\n",
    "    for a in rend:\n",
    "        if f == a[14]:\n",
    "            c.append(a)\n",
    "        else:\n",
    "            out.append(c)\n",
    "            c = [a]\n",
    "            f = (a[14]) \n",
    "    \n",
    "    out.append(c)\n",
    "    out.pop(0)\n",
    "    final_df[\"Ren\"] = final_df[\"ren_id\"].apply(lambda x: random.choice(out[int(x)-1]))\n",
    "    rend = (list(dfRendChoices.columns))\n",
    "    del dfRendChoices\n",
    "    \n",
    "    num_lines= final_df.shape[0]\n",
    "    #This creates a dataframe of useful info regarding the synthedic billing providers creating\n",
    "    #names and info randomly based on value specifications.\n",
    "    billing_list = bill_info(num_providers, taxonomy, bill_lst)\n",
    "    bill_lst = [\"BillingProviderID\", \"BillingProviderTIN\", \"BillingProviderOrg\", \"BillingProviderFName\",\n",
    "           \"BillingProviderMName\", \"BillingProviderLName\", \"BillingProviderPhoneNumber\", \n",
    "           \"BillingProviderAddressLine1\", \"BillingProviderAddressLine2\",\"BillingProviderEntityType\",\n",
    "           \"BillingProviderNPI\",'BillingProviderTaxonomy']\n",
    "    # basic df for info on groups for the patinets to be part of. Probably will move to patient data\n",
    "    group_list = group_info(num_providers)\n",
    "\n",
    "    print(\"end of billing prov info generation\")\n",
    "    \n",
    "    #Null data for Professional which is populated in Dental or facility data or has been decided \n",
    "    #to not be important in the data.\n",
    "\n",
    "    final_df[null_list] = \"\"\n",
    "    final_df[\"RelatedHospAdmitDate\"] =\"\"\n",
    "    final_df[\"BillingProviderSpecialtyCode\"]=str(taxonomy)\n",
    "    final_df[\"RenderingProviderSpecialtyCode\"]=str(taxonomy)\n",
    "    final_df[\"ClaimType\"] = \"D\" #P for profesional, D for dental, F for facility\n",
    "    final_df[\"InterPlan\"] = np.random.choice([\"Host\", \"ITS\", \"nonITS\"], num_lines, p=[0.4, 0.3,0.3])\n",
    "    final_df[\"ASOFlag\"] = np.random.choice([\"Y\", \"N\"], num_lines, p=[0.5, 0.5])\n",
    "    final_df[\"CapEpcIndicator\"] = np.random.choice([\"Y\", \"N\"], num_lines, p=[0.2, 0.8])\n",
    "    final_df[\"DenyFlag\"] = np.random.choice([\"Y\", \"N\"], num_lines, p=[0.003, 0.997])\n",
    "    final_df[\"InterPlan\"] = np.random.choice([\"ITS\", \"nonITS\", \"HOST\"], num_lines, p=[0.3, 0.4, 0.3])\n",
    "    final_df[\"ReferringProviderNPI\"] = np.random.randint(1000000000, 9999999999, size=final_df.shape[0])\n",
    "    final_df[\"NumofAdjustments\"]= np.random.exponential(.5, size=num_lines).astype(int)# can be edited to \n",
    "    #change rate of edits violations\n",
    "    final_df[\"PayeeType\"] =\"Prov\"\n",
    "    final_df[\"ICDVersion\"] = \"ICD-10\"\n",
    "    \n",
    "    #Chooses billing provider and group for the calim, again likely to change this as group sholuld be \n",
    "    #attached to patient.\n",
    "    final_df[\"Billing\"] = np.random.choice(billing_list, size=num_lines)\n",
    "    final_df[\"Group\"] = np.random.choice(group_list, size=num_lines)\n",
    "    \n",
    "    #Below calculates dates for the claims and is based on at most 2 years ago and a minimum start date \n",
    "    #of 1 month prior to current to mainatin 24 months of coverage.\n",
    "    final_df = claim_date(final_df)\n",
    "    \n",
    "    #Function to split concatenated cells into lists to be better used.\n",
    "    splitting(\"Billing\")\n",
    "    splitting(\"Group\")\n",
    "    print(\"End of Splitting\")\n",
    "    #Splitting lists made directly above into columns in the data.\n",
    "    final_df[bill_lst] = pd.DataFrame(final_df.pop('Billing').values.tolist(), index=final_df.index)\n",
    "    final_df[[\"GroupName\",\"GroupNumber\"]] = pd.DataFrame(final_df.pop('Group').values.tolist(), index=final_df.index)\n",
    "    final_df[rend] = pd.DataFrame(final_df.pop('Ren').values.tolist(), index=final_df.index)\n",
    "    #Make patient ID equal subscriber ID if they are the same person.\n",
    "    \n",
    "    #Set address info to null if no zip code.\n",
    "    final_df[\"BillingProviderZipCode\"]= final_df[\"BillingProviderZipCode\"].astype(str)\n",
    "    final_df[\"RenderingProviderZipCode\"]=  final_df[\"RenderingProviderZipCode\"].astype(str)\n",
    "    final_df[\"BillingProviderState\"] = final_df[\"BillingProviderState\"].astype(str)\n",
    "    final_df[\"RenderingProviderState\"]= final_df[\"RenderingProviderState\"].astype(str)\n",
    "    final_df[\"BillingProviderZipCode\"]= final_df[\"BillingProviderZipCode\"].replace(['0'],\n",
    "                                                                                   np.nan, regex=True, inplace=True)\n",
    "    final_df[\"RenderingProviderZipCode\"]=  final_df[\"RenderingProviderZipCode\"].replace(['0'],\n",
    "                                                                                   np.nan, regex=True, inplace=True)\n",
    "    final_df[\"BillingProviderState\"] = final_df[\"BillingProviderState\"].str.replace('0.0','')\n",
    "    final_df[\"RenderingProviderState\"]= final_df[\"RenderingProviderState\"].str.replace('0.0','')\n",
    "    final_df[\"SubscriberState\"] = final_df[\"SubscriberState\"].astype(str)\n",
    "\n",
    "    print(final_df.shape[0])\n",
    "    \n",
    "    #Split final DF based on age and gender so that a patient can be reasonably assigned to match the claim info.\n",
    "\n",
    "    print(\"States for patients\")\n",
    "    final_df = pat_states(final_df)\n",
    "    print(final_df.shape[0])\n",
    "    splitting(\"Pat\")\n",
    "    \n",
    "    final_df[pat_lst] = pd.DataFrame(final_df.pop('Pat').values.tolist(), index=final_df.index)\n",
    "    final_df = pat_relationship(final_df)\n",
    "    #Set address info to null if no zip code.\n",
    "    final_df = bill_prov_null_zip(final_df)\n",
    "    \n",
    "    final_df =  final_df.loc[(final_df['PatientID'] != \"\")]\n",
    "    bad_df = final_df.loc[(final_df['super_bad'] == 'Y')]\n",
    "    \n",
    "    sb_out_lst = bad_df['RenderingProviderNPI'].tolist()\n",
    "    sb_out_lst = list(set(sb_out_lst))\n",
    "    \n",
    "    ###need to add time increase\n",
    "    #calculates insurance based on age, elderly on medicare and Commercial plus whereas younger \n",
    "    #patients have mainly Commercial and Commercial plus with only a few on medicare.\n",
    "    final_df = insurance_type(final_df)\n",
    "\n",
    "    print(\"start of peppering\")\n",
    "    combo_list = final_df[\"combos\"].tolist()\n",
    "    final_df[\"APCCode\"] = \"\"\n",
    "    #Area for peppering new data with detector problems, done prior to line seperation\n",
    "    #time decrease\n",
    "    final_df = claim_peppering(final_df)\n",
    "    \n",
    "    print(\"End of Peppering\")\n",
    "    \n",
    "    final_df = line_nums(final_df)\n",
    "    \n",
    "    print(\"Claim Line seperated\")\n",
    "    #Accounts for the case rendering is billing prov\n",
    "    final_df = ren_is_bill(final_df)\n",
    " \n",
    "    final_df = final_df.sort_values(by=\"AdmitDate\")\n",
    "    final_df = final_df.sort_values(by=\"RenderingProviderTIN\")\n",
    "    final_df = final_df.sort_values(by=\"combos\")\n",
    "    final_df['combos'] = final_df['combos'].astype(str)\n",
    "    final_df = final_df.loc[(final_df['combos'] != \"\")]\n",
    "    final_df = final_df.drop_duplicates(subset = ['ClaimID', 'LineNumber'],keep = 'last').reset_index(drop = True)\n",
    "    final_df[\"PreAuthIndicator\"] =final_df[\"hcpcs_code\"].apply(lambda x: preauth(x))\n",
    "    srvs_df = pd.read_csv(srvs_csv)\n",
    "    dfNew = pd.DataFrame()\n",
    "    objMissingCombos = []\n",
    "    dfComboSize = final_df.groupby(['combos'], as_index=False).size()\n",
    "    srvs_df = srvs_df.merge(dfComboSize)\n",
    "    print(dfComboSize.shape[0])\n",
    "    k =0\n",
    "    for index, row in dfComboSize.iterrows():\n",
    "        k+=1\n",
    "        if k%600 == 0:\n",
    "            print(k)\n",
    "        combo = row['combos']\n",
    "        dfCombos = srvs_df[srvs_df['combos'] == combo]\n",
    "        objCombos = dfCombos.drop(['percent'], axis = 1).values\n",
    "        objWeights = dfCombos['percent'].tolist()\n",
    "        intSize = row['size']\n",
    "        objCols = dfCombos.drop(['percent'], axis=1).columns\n",
    "        if len(objCombos) > 0:\n",
    "            dfNewTmp = pd.DataFrame(random.choices(objCombos, objWeights, k=row['size']),\n",
    "                                columns=objCols)\n",
    "            dfNew = dfNew.append(dfNewTmp)\n",
    "        else:\n",
    "            objMissingCombos.append([combo, 1, intSize])\n",
    "    if len(objMissingCombos) > 0:\n",
    "        dfMissing = pd.DataFrame(objMissingCombos, columns=['combos', 'srvc_cnt', 'size_out'])\n",
    "        dfMissing = dfMissing.loc[dfMissing.index.repeat(dfMissing.size_out)]\n",
    "        dfNew = dfNew.append(dfMissing)\n",
    "    dfSrvcCnts = dfNew[['combos', 'srvc_cnt']].sort_values('combos')\n",
    "    final_df = final_df.sort_values(['combos'])\n",
    "    objSrvcCnts = dfSrvcCnts['srvc_cnt'].tolist()\n",
    "    final_df['srvc_cnt_new'] = objSrvcCnts\n",
    "    \n",
    "    print(\"Line units merged\")\n",
    "    final_df = final_df.rename(columns={'srvc_cnt_new': 'LineUnits'})\n",
    "    final_df = final_df.rename(columns={'combos': 'combo'})\n",
    "    \n",
    "    final_df[\"combo\"] = final_df[\"hcpcs_code\"]+\";\"+final_df[\"ToothNumber\"]+\";\"+final_df[\"ToothBegin\"]+\";\"+final_df[\"ToothEnd\"]+\";\"+final_df[\"ToothSurfaces\"]\n",
    "    \n",
    "    print(\"Start of payment\")\n",
    "    #Starting to calculate the payment for each claim on both a line and claim level.\n",
    "\n",
    "    print(final_df.shape[0])\n",
    "    final_df = payments(final_df, c_amt_csv, d_amt_csv)\n",
    "\n",
    "    print(final_df.shape[0])\n",
    "    print(\"Payments done\")\n",
    "    final_df = hdr_pay(final_df)\n",
    "    \n",
    "    final_df = final_df.drop_duplicates(subset = ['ClaimID', 'LineNumber'])\n",
    "    \n",
    "    final_df[\"LineNumber\"]= final_df[\"LineNumber\"].astype(int)\n",
    "    final_df[\"AccidentDate\"]=final_df[\"AccidentDate\"].fillna(\"\")\n",
    "\n",
    "    final_df[\"ToothNumber\"] = final_df[\"ToothNumber\"].str[:-3]\n",
    "    final_df[\"ToothBegin\"] = final_df[\"ToothBegin\"].str[:-3]\n",
    "    final_df[\"ToothEnd\"] = final_df[\"ToothEnd\"].str[:-3]\n",
    "    final_df[\"ToothSurfaces\"] = final_df[\"ToothSurfaces\"].str[:-3]\n",
    "\n",
    "    final_df = tooth_order(final_df)\n",
    "\n",
    "    final_df=final_df.replace([np.inf, -np.inf], np.nan, inplace=False)\n",
    "    #reorders the columns to fit for data spec.\n",
    "    final_df = final_df[ordered_col_lst]\n",
    "    print(\"Starting saving\")\n",
    "    save_files(final_df, folder, taxonomy)\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5000031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call(['bash', 'Test.sh'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bed679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=16511291392, available=15245312000, percent=7.7, used=963719168, free=12415201280, active=1217085440, inactive=2638331904, buffers=143257600, cached=2989113344, shared=90112, slab=126803968)\n",
      "0\n",
      "149\n",
      "[0, 1, 2]\n",
      "Zipping\n",
      "zips located\n",
      "end of billing prov info generation\n",
      "End of Splitting\n",
      "77401\n",
      "States for patients\n",
      "77401\n",
      "start of peppering\n",
      "End of Peppering\n",
      "Claim Line seperated\n",
      "1464\n",
      "600\n",
      "1200\n",
      "Line units merged\n",
      "Start of payment\n",
      "193777\n",
      "193747\n",
      "193747\n",
      "Payments done\n",
      "LinePatientPaid\n",
      "LineTotPaid\n",
      "LinCharges\n",
      "HDR\n",
      "Starting saving\n",
      "1\n",
      "353\n",
      "[44, 0, 1, 2]\n",
      "Zipping\n",
      "zips located\n",
      "end of billing prov info generation\n",
      "End of Splitting\n",
      "141842\n",
      "States for patients\n",
      "141594\n",
      "start of peppering\n",
      "End of Peppering\n",
      "Claim Line seperated\n",
      "6127\n",
      "600\n",
      "1200\n",
      "1800\n",
      "2400\n",
      "3000\n",
      "3600\n",
      "4200\n",
      "4800\n",
      "5400\n",
      "6000\n",
      "Line units merged\n",
      "Start of payment\n",
      "340004\n",
      "340002\n",
      "340002\n",
      "Payments done\n",
      "LinePatientPaid\n",
      "LineTotPaid\n",
      "LinCharges\n",
      "HDR\n",
      "Starting saving\n",
      "3\n",
      "494\n",
      "[345, 0, 1, 2]\n",
      "Zipping\n",
      "zips located\n",
      "end of billing prov info generation\n",
      "End of Splitting\n",
      "235339\n",
      "States for patients\n",
      "235288\n",
      "start of peppering\n"
     ]
    }
   ],
   "source": [
    "#order for function\n",
    "#taxonomy \n",
    "#Folder\n",
    "import psutil\n",
    "print(psutil.virtual_memory())\n",
    "print(\"0\")#normally around 13-15\n",
    "#\n",
    "fin = syn_data(6, 'Anesthesiology',.8)\n",
    "print(\"1\")\n",
    "####fin = syn_data(84, 'Pathology',100)\n",
    "#print(\"2\")\n",
    "try:\n",
    "    syn_data(178, 'Oral_Surgery',.1)\n",
    "except:\n",
    "    syn_data(178, 'Oral_Surgery',.1)\n",
    "print(\"3\")\n",
    "try:\n",
    "    fin = syn_data(26, 'Dentist',.02)\n",
    "except:\n",
    "    fin = syn_data(26, 'Dentist',.01)\n",
    "######fail\n",
    "#try:\n",
    "#    syn_data(66,'Nuclear_Radiology',50)\n",
    "#except:\n",
    "#    print(\"Nuclear_Radiology failed#########################\")\n",
    "#print(\"4\")\n",
    "#try:\n",
    "#    syn_data(70, 'Obstetrics_Gynecology',50)\n",
    "#except:\n",
    "#    print(\"Obstetrics_Gynecology failed#########################\")\n",
    "#print(\"5\")\n",
    "#try:\n",
    "#    syn_data(72, 'Ophthalmology',50)\n",
    "#except:\n",
    "#    print(\"Ophthalmology failed#########################\")\n",
    "#print(\"6\")\n",
    "#try:\n",
    "#    syn_data(75, 'Orthopaedic_Surgery',50)\n",
    "#except:\n",
    "#    print(\"Orthopaedic_Surgery failed#########################\")\n",
    "#print(\"7\")\n",
    "#try:\n",
    "#    fin = syn_data(84, 'Pathology',50)\n",
    "#except:\n",
    "#    print(\"Pathology failed#########################\")\n",
    "#print(\"8\")\n",
    "#try:\n",
    "#    syn_data(121, 'Psychiatry_Neurology',50)\n",
    "#except:\n",
    "#    print(\"Psychiatry_Neurology failed#########################\")\n",
    "#print(\"9\")\n",
    "#try:\n",
    "#    fin = syn_data(108, 'Pediatrics',50)\n",
    "#except:\n",
    "#    print(\"Pediatrics failed#########################\")\n",
    "#print(\"10\")\n",
    "#\n",
    "i = 0\n",
    "while i < 23:\n",
    "    i+=1\n",
    "    print(i)\n",
    "    all_filenames = [\"Out/Dental/\"+str(i)+\"/Anesthesiology_Month_\"+str(i)+\".csv\", \"Out/Dental/\"+str(i)+\"/Oral_Surgery_Month_\"+str(i)+\".csv\", \"Out/Dental/\"+str(i)+\"/Dentist_Month_\"+str(i)+\".csv\"]#, \"Out/Dental/\"+str(i)+\"/Nuclear_Radiology_Month_\"+str(i)+\".csv\", \"Out/Dental/\"+str(i)+\"/Obstetrics_Gynecology_Month_\"+str(i)+\".csv\", \"Out/Dental/\"+str(i)+\"/Ophthalmology_Month_\"+str(i)+\".csv\", \"Out/Dental/\"+str(i)+\"/Orthopaedic_Surgery_Month_\"+str(i)+\".csv\", \"Out/Dental/\"+str(i)+\"/Pathology_Month_\"+str(i)+\".csv\", \"Out/Dental/\"+str(i)+\"/Pediatrics_Month_\"+str(i)+\".csv\", \"Out/Dental/\"+str(i)+\"/Psychiatry_Neurology_Month_\"+str(i)+\".csv\"]\n",
    "    df = pd.concat((pd.read_csv(f, header = 0) for f in all_filenames))\n",
    "    df = df.drop_duplicates(subset = ['ClaimID', 'LineNumber'],keep = 'last').reset_index(drop = True)\n",
    "    df[\"PatientGender\"] = df[\"PatientGender.1\"]\n",
    "    \n",
    "    df[\"ToothNumber\"] = df[\"ToothNumber\"].str[:-3]\n",
    "    df[\"ToothBegin\"] = df[\"ToothBegin\"].str[:-3]\n",
    "    df[\"ToothEnd\"] = df[\"ToothEnd\"].str[:-3]\n",
    "    df[\"ToothSurfaces\"] = df[\"ToothSurfaces\"].str[:-3]\n",
    "    \n",
    "    df = df.drop(columns=['PatientGender.1'])\n",
    "    df1 = df.loc[(df['PatientRelationship'] == 'Subscriber')]\n",
    "    df2 = df.loc[(df['PatientRelationship'] != 'Subscriber')]\n",
    "    df1['SubscriberLName'] = df1['PatientLName']\n",
    "    df1['SubscriberFName'] = df1['PatientFName']\n",
    "    df1['SubscriberMName'] = df1['PatientMName']\n",
    "    df = pd.concat([df1, df2])\n",
    "    df1 = df.loc[(df['RenderingProviderState'] == '')]\n",
    "    df2 = df.loc[(df['RenderingProviderState'] != '')]\n",
    "    df1['RenderingProviderState'] = df1[\"PatientState\"]\n",
    "    df = pd.concat([df1, df2])\n",
    "    strBucket = 'data-science-synthdata-dev'\n",
    "    strTestFile =\"Dental/Month_\"+ str(i)+\".csv\"\n",
    "    strOutFile = 's3://{}/{}'.format(strBucket, strTestFile)\n",
    "    df.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "    df.to_csv(\"Out/Dental/To_s3/Prof\"+str(i)+\".csv\", index=False)\n",
    "\n",
    "fold_lst1=[\"Out/Dental/Anesthesiology_provider_file1.csv\", \"Out/Dental/Oral_Surgery_provider_file1.csv\", \"Out/Dental/Dentist_provider_file1.csv\"]#, \"Out/Professional/Nuclear_Radiology_provider_file1.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file1.csv\", \"Out/Professional/Ophthalmology_provider_file1.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file1.csv\", \"Out/Professional/Pathology_provider_file1.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file1.csv\", \"Out/Professional/Pediatrics_provider_file1.csv\"]\n",
    "combined_csv = pd.concat([pd.read_csv(f, header=0) for f in fold_lst1 ])\n",
    "combined_csv = combined_csv.drop_duplicates()\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Dental/predicted_claim_spec_synthetic.csv\")\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "\n",
    "fold_lst2=[\"Out/Dental/Anesthesiology_provider_file2.csv\", \"Out/Dental/Oral_Surgery_provider_file2.csv\", \"Out/Dental/Dentist_provider_file2.csv\"]#, \"Out/Professional/Nuclear_Radiology_provider_file2.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file2.csv\", \"Out/Professional/Ophthalmology_provider_file2.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file2.csv\", \"Out/Professional/Pathology_provider_file2.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file2.csv\", \"Out/Professional/Pediatrics_provider_file2.csv\"]\n",
    "combined_csv_2 = pd.concat([pd.read_csv(f, header=0) for f in fold_lst2 ])\n",
    "combined_csv_2 = combined_csv_2.drop_duplicates()\n",
    "combined_csv = combined_csv.append(combined_csv_2).drop_duplicates()\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Dental/predicted_provider_spec_synthetic.csv\")\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "\n",
    "fin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26436637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin = pd.read_csv(\"Out/Professional/Orthopaedic_Surgery.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22488802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357bc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c42464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_network(x):\n",
    "    if x ==\"PAR\":\n",
    "        return \"N\"\n",
    "    return \"Y\"\n",
    "ren_df = pd.read_csv(\"Input/Professional/ren_provider_overlap_cnts.csv\")\n",
    "ren_df = ren_df.sort_values(by=['perc'], ascending=False)\n",
    "ren_dict =dict(ren_df.values)\n",
    "\n",
    "\n",
    "num_providers = 100000#may want to edit this\n",
    "rendering_df = pd.DataFrame()\n",
    "rendering_df[\"RenderingProviderEntityType\"] = np.random.choice([\"I\", \"O\"], num_providers, p=[0.9, 0.1])\n",
    "rendering_df['RenderingProviderPhoneNumber'] = [fake.msisdn() for i in range(num_providers)]\n",
    "rendering_df['RenderingProviderTIN']= np.random.randint(100000000,999999999, size=num_providers)\n",
    "rendering_df[\"RenderingProviderID\"] = np.random.randint(10000,999999, size=num_providers)\n",
    "rendering_df[\"RenderingProviderID\"] = rendering_df[\"RenderingProviderID\"].astype(str)\n",
    "rendering_df[\"ContractedFlag\"] = np.random.choice(['PAR','NONPAR'], num_providers, p=[0.8, 0.2])\n",
    "rendering_df[\"OutOfNetwork\"]  = rendering_df[\"ContractedFlag\"].apply(lambda x: in_network(x))\n",
    "rendering_df['1'] = [fake.building_number() for i in range(num_providers)]\n",
    "rendering_df[\"2\"] = [fake.street_name() for i in range(num_providers)]\n",
    "rendering_df['RenderingProviderAddressLine1'] = rendering_df[\"1\"]+\" \"+rendering_df[\"2\"]\n",
    "rendering_df[\"1\"] = np.random.choice([\"Suite\", \"Apt.\", \"Null\"], num_providers, p=[0.05, 0.15, 0.8])\n",
    "rendering_df[\"2\"] = [fake.building_number() for i in range(num_providers)]\n",
    "rendering_df[\"RenderingProviderAddressLine2\"] = rendering_df[\"1\"]+\" \"+rendering_df[\"2\"]\n",
    "rendering_df.loc[rendering_df['RenderingProviderAddressLine2'].str.contains('Null', case=False),\n",
    "                 'RenderingProviderAddressLine2'] = ''\n",
    "\n",
    "org1_df = rendering_df.loc[(rendering_df['RenderingProviderEntityType'] == 'O')]\n",
    "ind1_df = rendering_df.loc[(rendering_df['RenderingProviderEntityType'] == 'I')]\n",
    "ind1_df['RenderingProviderOrg'] = \"\"\n",
    "ind1_df['RenderingProviderFName'] = [fake.first_name() for i in range(ind1_df.shape[0])]\n",
    "ind1_df['RenderingProviderMName'] = [fake.first_name() for i in range(ind1_df.shape[0])]\n",
    "ind1_df['RenderingProviderLName'] = [fake.last_name() for i in range(ind1_df.shape[0])]\n",
    "\n",
    "org1_df['RenderingProviderOrg'] = np.random.choice(org_lst, size=org1_df.shape[0])\n",
    "org1_df['RenderingProviderFName'] =\"\"\n",
    "org1_df['RenderingProviderMName'] =\"\"\n",
    "org1_df['RenderingProviderLName'] =\"\"\n",
    "rendering_df= pd.concat([org1_df, ind1_df])\n",
    "\n",
    "rendering_df['RenderingProviderPhoneNumber'] = rendering_df['RenderingProviderPhoneNumber'].astype(str)\n",
    "rendering_df['RenderingProviderTIN'] = rendering_df['RenderingProviderTIN'].astype(str)\n",
    "rendering_df[\"CCN\"] = np.random.randint(0,38000, size=num_providers)\n",
    "rendering_df[\"CCN\"] = rendering_df[\"CCN\"].apply(lambda x: '{0:0>5}'.format(x))\n",
    "rendering_df[\"RenderingProviderNPI\"] = np.random.randint(1000000000, 9999999999, size=num_providers)\n",
    "rendering_df[\"RenderingProviderNPI\"] = rendering_df[\"RenderingProviderNPI\"].astype(str)\n",
    "rendering_df['RenderingProviderTIN'] = rendering_df['RenderingProviderTIN'].astype(str)\n",
    "rendering_df[\"RenderingProviderID\"] = rendering_df[\"RenderingProviderID\"].astype(str)\n",
    "rendering_df[\"CCN\"] =rendering_df[\"CCN\"].astype(str)\n",
    "\n",
    "rendering_df[\"REN\"] =rendering_df[\"RenderingProviderEntityType\"]+\"@\"+rendering_df[\"RenderingProviderPhoneNumber\"]+\"@\"+rendering_df[\"RenderingProviderTIN\"]+\"@\"+rendering_df[\"RenderingProviderID\"]+\"@\"+rendering_df[\"ContractedFlag\"]+\"@\"+rendering_df[\"OutOfNetwork\"]+\"@\"+rendering_df[\"RenderingProviderAddressLine1\"]+\"@\"+rendering_df[\"RenderingProviderAddressLine2\"]+\"@\"+rendering_df[\"RenderingProviderOrg\"]+\"@\"+rendering_df[\"RenderingProviderFName\"]+\"@\"+rendering_df[\"RenderingProviderMName\"]+\"@\"+rendering_df[\"RenderingProviderLName\"]+\"@\"+rendering_df[\"CCN\"]+\"@\"+rendering_df[\"RenderingProviderNPI\"]\n",
    "rendering_df = rendering_df.drop(columns=[\"RenderingProviderEntityType\",\"RenderingProviderPhoneNumber\",\n",
    "                                          \"RenderingProviderTIN\",\"RenderingProviderID\",\"ContractedFlag\",\n",
    "                                          \"OutOfNetwork\",\"RenderingProviderAddressLine1\",\n",
    "                                          \"RenderingProviderAddressLine2\",\"RenderingProviderOrg\",\n",
    "                                          \"RenderingProviderFName\",\"RenderingProviderMName\",\"RenderingProviderLName\",\n",
    "                                          \"CCN\",\"RenderingProviderNPI\"])\n",
    "rendering_df[\"Tax\"] = np.random.choice(list(ren_dict.keys()),num_providers, p=list(ren_dict.values()))\n",
    "rendering_df.to_csv(\"Input/rendering_prov.csv\", index=False)\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "billing_df = pd.DataFrame()\n",
    "bill_df = pd.read_csv(\"Input/Professional/bill_provider_overlap_cnts.csv\")\n",
    "bill_df = bill_df.sort_values(by=['perc'], ascending=False)\n",
    "bill_dict =dict(bill_df.values)\n",
    "\n",
    "\n",
    "billing_df[\"BillingProviderID\"] = np.random.randint(10000,999999, size=num_providers//6)\n",
    "billing_df[\"BillingProviderTIN\"] = np.random.randint(100000000,999999999, size=num_providers//6)\n",
    "billing_df['BillingProviderPhoneNumber'] = [fake.msisdn() for i in range(num_providers//6)]\n",
    "billing_df[\"BillingProviderEntityType\"] = np.random.choice([\"I\", \"O\"], num_providers//6, p=[0.9, 0.1])\n",
    "#split billing to deal with individual vs orginizations diffrently\n",
    "org_df = billing_df.loc[(billing_df['BillingProviderEntityType'] == 'O')]\n",
    "ind_df= billing_df.loc[(billing_df['BillingProviderEntityType'] == 'I')]\n",
    "\n",
    "ind_df['BillingProviderFName'] = [fake.first_name() for i in range(ind_df.shape[0])]\n",
    "ind_df['BillingProviderMName'] = [fake.first_name() for i in range(ind_df.shape[0])]\n",
    "ind_df['BillingProviderLName'] = [fake.last_name() for i in range(ind_df.shape[0])]\n",
    "ind_df[\"BillingProviderOrg\"]  = \"\"\n",
    "org_df[\"BillingProviderOrg\"] = np.random.choice(org_lst, size=org_df.shape[0])\n",
    "org_df['BillingProviderFName'] = \"\"\n",
    "org_df['BillingProviderMName'] = \"\"\n",
    "org_df['BillingProviderLName'] = \"\"\n",
    "billing_df = pd.concat([org_df, ind_df])\n",
    "\n",
    "billing_df[\"BillingProviderNPI\"]  = np.random.randint(1000000000, 9999999999, size=num_providers//6)\n",
    "billing_df['1'] = [fake.building_number() for i in range(num_providers//6)]\n",
    "billing_df[\"2\"] = [fake.street_name() for i in range(num_providers//6)]\n",
    "billing_df['BillingProviderAddressLine1'] = billing_df[\"1\"]+\" \"+billing_df[\"2\"]\n",
    "billing_df[\"1\"] = np.random.choice([\"Suite\", \"Apt.\", \"Null\"], num_providers//6, p=[0.05, 0.15, 0.8])\n",
    "billing_df[\"2\"] = [fake.building_number() for i in range(num_providers//6)]\n",
    "billing_df[\"BillingProviderAddressLine2\"] = billing_df[\"1\"]+\" \"+billing_df[\"2\"]\n",
    "billing_df.loc[billing_df['BillingProviderAddressLine2'].str.contains('Null', case=False), \n",
    "               'BillingProviderAddressLine2'] = ''\n",
    "billing_df = billing_df.drop(columns=['1',\"2\"])\n",
    "billing_df[\"BillingProviderNPI\"] = billing_df[\"BillingProviderNPI\"].astype(str)\n",
    "billing_df['BillingProviderID'] = billing_df['BillingProviderID'].astype(str)\n",
    "billing_df['BillingProviderTIN'] = billing_df['BillingProviderTIN'].astype(str)\n",
    "\n",
    "billing_df[\"BILL\"] = billing_df[\"BillingProviderID\"]+\"@\"+billing_df[\"BillingProviderTIN\"]+\"@\"+billing_df[\"BillingProviderOrg\"]+\"@\"+billing_df[\"BillingProviderFName\"]+\"@\"+billing_df[\"BillingProviderMName\"]+\"@\"+billing_df[\"BillingProviderLName\"]+\"@\"+billing_df[\"BillingProviderPhoneNumber\"]+\"@\"+billing_df[\"BillingProviderAddressLine1\"]+\"@\"+billing_df[\"BillingProviderAddressLine2\"]+\"@\"+billing_df[\"BillingProviderEntityType\"]+\"@\"+billing_df[\"BillingProviderNPI\"]\n",
    "billinb_df = billing_df.drop(columns = [\"BillingProviderID\",\"BillingProviderTIN\",\"BillingProviderOrg\",\n",
    "                                        \"BillingProviderFName\",\"BillingProviderMName\",\"BillingProviderLName\",\n",
    "                                        \"BillingProviderPhoneNumber\",\"BillingProviderAddressLine1\",\n",
    "                                        \"BillingProviderAddressLine2\",\"BillingProviderEntityType\",\n",
    "                                        \"BillingProviderNPI\"])\n",
    "\n",
    "billing_df[\"Tax\"] = np.random.choice(list(bill_dict.keys()),num_providers//6, p=list(bill_dict.values()))\n",
    "billing_df.to_csv(\"Input/billing_prov.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145f713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a986440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d6656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52ea15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2c1a035",
   "metadata": {},
   "source": [
    "i = 23\n",
    "while i < 24:\n",
    "    i+=1\n",
    "    print(i)\n",
    "    strBucket = 'data-science-synthdata-dev'\n",
    "    strTestFile =\"Professional/tmp_outlier_provs/Month_\"+ str(i)+\".csv\"\n",
    "    strOutFile = 's3://{}/{}'.format(strBucket, strTestFile)\n",
    "    \n",
    "    final_df = pd.read_csv(strOutFile, sep=\"|\")\n",
    "    #final_df['paid']=final_df['paid'].where(final_df['paid'] <= 10000000, 10000000)\n",
    "    final_df[\"LineNumber\"]= final_df[\"LineNumber\"].astype(int)\n",
    "    final_df[\"AccidentDate\"]=final_df[\"AccidentDate\"].fillna(\"\")\n",
    "    final_df[\"HdrCharges\"]=final_df[\"HdrCharges\"].where(final_df['HdrCharges'] <= 10000000, 10000000)\n",
    "    final_df[\"LineCharges\"]=final_df[\"LineCharges\"].where(final_df['LineCharges'] <= 10000000, 10000000)\n",
    "    final_df[\"HdrPayerPay\"]=final_df[\"HdrPayerPay\"].where(final_df['HdrPayerPay'] <= 10000000, 10000000)\n",
    "    final_df[\"HdrCOBPay\"]=final_df[\"HdrCOBPay\"].where(final_df['HdrCOBPay'] <= 10000000, 10000000)\n",
    "    final_df[\"HdrPatientCopay\"]=final_df[\"HdrPatientCopay\"].where(final_df['HdrPatientCopay'] <= 10000000, 10000000)\n",
    "    final_df[\"HdrPatientPay\"]=final_df[\"HdrPatientPay\"].where(final_df['HdrPatientPay'] <= 10000000, 10000000)\n",
    "    final_df[\"HdrPay\"]=final_df[\"HdrPay\"].where(final_df['HdrPay'] <= 10000000, 10000000)\n",
    "    final_df[\"LinePatientPaid\"]=final_df[\"LinePatientPaid\"].where(final_df['LinePatientPaid'] <= 10000000, 10000000)\n",
    "    final_df[\"LineAmountCoinsurance\"]=final_df[\"LineAmountCoinsurance\"].where(final_df['LineAmountCoinsurance'] <= 10000000, 10000000)\n",
    "    final_df[\"LineAmountCopay\"]=final_df[\"LineAmountCopay\"].where(final_df['LineAmountCopay'] <= 10000000, 10000000)\n",
    "    final_df[\"LineAmountDeductible\"]=final_df[\"LineAmountDeductible\"].where(final_df['LineAmountDeductible'] <= 10000000, 10000000)\n",
    "    final_df[\"LineCharges\"]=final_df[\"LineCharges\"].where(final_df['LineCharges'] <= 10000000, 10000000)\n",
    "    final_df[\"LinePayerPaid\"]=final_df[\"LinePayerPaid\"].where(final_df['LinePayerPaid'] <= 10000000, 10000000)\n",
    "    final_df[\"LineCOBPay\"]=final_df[\"LineCOBPay\"].where(final_df['LineCOBPay'] <= 10000000, 10000000)\n",
    "    final_df[\"LineTotPaid\"]=final_df[\"LineTotPaid\"].where(final_df['LineTotPaid'] <= 10000000, 10000000)\n",
    "    final_df[\"LineConsideredAmount\"]=final_df[\"LineConsideredAmount\"].where(final_df['LineConsideredAmount'] <= 10000000, 10000000)\n",
    "    final_df[\"LineAllowedAmount\"]=final_df[\"LineAllowedAmount\"].where(final_df['LineAllowedAmount'] <= 10000000, 10000000)\n",
    "    \n",
    "    \n",
    "    strBucket = 'data-science-synthdata-dev'\n",
    "    strTestFile =\"Professional/Month_\"+ str(i)+\".csv\"\n",
    "    strOutFile = 's3://{}/{}'.format(strBucket, strTestFile)\n",
    "    final_df.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5331ec",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "i = 0\n",
    "while i < 23:\n",
    "    i+=1\n",
    "    print(i)\n",
    "    all_filenames = [\"Out/Professional/\"+str(i)+\"/Anesthesiology_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Counseling_Psychology_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Emergency_Medicine_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Nuclear_Radiology_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Obstetrics_Gynecology_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Ophthalmology_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Orthopaedic_Surgery_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Pathology_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Pediatrics_Month_\"+str(i)+\".csv\", \"Out/Professional/\"+str(i)+\"/Psychiatry_Neurology_Month_\"+str(i)+\".csv\"]\n",
    "    df = pd.concat((pd.read_csv(f, header = 0) for f in all_filenames))\n",
    "    df = df.drop_duplicates(subset = ['ClaimID', 'LineNumber'],keep = 'last').reset_index(drop = True)\n",
    "    strBucket = 'data-science-synthdata-dev'\n",
    "    strTestFile =\"Professional/Month_\"+ str(i)+\".csv\"\n",
    "    strOutFile = 's3://{}/{}'.format(strBucket, strTestFile)\n",
    "    df.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "    df.to_csv(\"Out/Professional/To_s3/Prof\"+str(i)+\".csv\", index=False)\n",
    "\n",
    "fold_lst1=[\"Out/Professional/Anesthesiology_provider_file1.csv\", \"Out/Professional/Counseling_Psychology_provider_file1.csv\", \"Out/Professional/Emergency_Medicine_provider_file1.csv\", \"Out/Professional/Nuclear_Radiology_provider_file1.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file1.csv\", \"Out/Professional/Ophthalmology_provider_file1.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file1.csv\", \"Out/Professional/Pathology_provider_file1.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file1.csv\", \"Out/Professional/Pediatrics_provider_file1.csv\"]\n",
    "fold_lst2=[\"Out/Professional/Anesthesiology_provider_file2.csv\", \"Out/Professional/Counseling_Psychology_provider_file2.csv\", \"Out/Professional/Emergency_Medicine_provider_file2.csv\", \"Out/Professional/Nuclear_Radiology_provider_file2.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file2.csv\", \"Out/Professional/Ophthalmology_provider_file2.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file2.csv\", \"Out/Professional/Pathology_provider_file2.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file2.csv\", \"Out/Professional/Pediatrics_provider_file2.csv\"]\n",
    "combined_csv = pd.concat([pd.read_csv(f, header=0) for f in fold_lst1 ])\n",
    "combined_csv = combined_csv.drop_duplicates()\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Professional/predicted_provider_spec_synthetic.csv\")\n",
    "\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "combined_csv = pd.concat([pd.read_csv(f, header=0) for f in fold_lst2 ])\n",
    "combined_csv = combined_csv.drop_duplicates()\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Professional/predicted_claim_spec_synthetic.csv\")\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e177a",
   "metadata": {},
   "source": [
    "all_filenames = [\"Anesthesiology\", \"Counseling_Psychology\", \"Emergency_Medicine\", \"Nuclear_Radiology\", \"Obstetrics_Gynecology\", \"Ophthalmology\", \"Orthopaedic_Surgery\", \"Pathology\", \"Pediatrics\", \"Psychiatry_Neurology\"]\n",
    "for a in all_filenames:\n",
    "    final_df = pd.read_csv(\"Out/Professional/\"+a+\".csv\")\n",
    "    out = final_df\n",
    "    out = out.drop(columns=['Date'])\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    c = \"\"\n",
    "    for index, row in final_df.iterrows():\n",
    "        j+=1\n",
    "        if not (c ==row[\"Date\"]):\n",
    "            c = row[\"Date\"]\n",
    "            if k!=0:\n",
    "                print(i)\n",
    "                strBucket = 'data-science-synthdata-dev'\n",
    "                strTestFile = \"Out/Professional/\"+str(i)+\"/\"+ a +\"_Month_\"+str(i)+'.csv'\n",
    "                strOutFile = 's3://{}/{}'.format(strBucket, strTestFile)\n",
    "                out.iloc[k:j-1].to_csv(strTestFile, index=False)\n",
    "            k = j\n",
    "            i+=1\n",
    "    #final_df.to_csv(\"Out/Professional/\"+str(a)+\".csv\",  index=False)#sep=\"|\",\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31487b",
   "metadata": {},
   "source": [
    "fold_lst1=[\"Out/Professional/Anesthesiology_provider_file1.csv\", \"Out/Professional/Counseling_Psychology_provider_file1.csv\", \"Out/Professional/Emergency_Medicine_provider_file1.csv\", \"Out/Professional/Nuclear_Radiology_provider_file1.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file1.csv\", \"Out/Professional/Ophthalmology_provider_file1.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file1.csv\", \"Out/Professional/Pathology_provider_file1.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file1.csv\", \"Out/Professional/Pediatrics_provider_file1.csv\"]\n",
    "combined_csv = pd.concat([pd.read_csv(f, header=0) for f in fold_lst1 ])\n",
    "combined_csv = combined_csv.drop_duplicates()\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Professional/predicted_provider_spec_synthetic1.csv\")\n",
    "\n",
    "fold_lst2=[\"Out/Professional/Anesthesiology_provider_file2.csv\", \"Out/Professional/Counseling_Psychology_provider_file2.csv\", \"Out/Professional/Emergency_Medicine_provider_file2.csv\", \"Out/Professional/Nuclear_Radiology_provider_file2.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file2.csv\", \"Out/Professional/Ophthalmology_provider_file2.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file2.csv\", \"Out/Professional/Pathology_provider_file2.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file2.csv\", \"Out/Professional/Pediatrics_provider_file2.csv\"]\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "combined_csv = pd.concat([pd.read_csv(f, header=0) for f in fold_lst2 ])\n",
    "combined_csv = combined_csv.drop_duplicates()\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Professional/predicted_claim_spec_synthetic2.csv\")\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa58bb",
   "metadata": {},
   "source": [
    "print(\"!\")\n",
    "fold_lst1=[\"Out/Professional/Anesthesiology_provider_file1.csv\", \"Out/Professional/Counseling_Psychology_provider_file1.csv\", \"Out/Professional/Emergency_Medicine_provider_file1.csv\", \"Out/Professional/Nuclear_Radiology_provider_file1.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file1.csv\", \"Out/Professional/Ophthalmology_provider_file1.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file1.csv\", \"Out/Professional/Pathology_provider_file1.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file1.csv\", \"Out/Professional/Pediatrics_provider_file1.csv\"]\n",
    "fold_lst2=[\"Out/Professional/Anesthesiology_provider_file2.csv\", \"Out/Professional/Counseling_Psychology_provider_file2.csv\", \"Out/Professional/Emergency_Medicine_provider_file2.csv\", \"Out/Professional/Nuclear_Radiology_provider_file2.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file2.csv\", \"Out/Professional/Ophthalmology_provider_file2.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file2.csv\", \"Out/Professional/Pathology_provider_file2.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file2.csv\", \"Out/Professional/Pediatrics_provider_file2.csv\"]\n",
    "combined_csv = pd.concat([pd.read_csv(f, header=0) for f in fold_lst1 ])\n",
    "combined_csv = combined_csv.drop_duplicates()\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Professional/predicted_provider_spec_synthetic.csv\")\n",
    "\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "combined_csv = pd.concat([pd.read_csv(f, header=0) for f in fold_lst2 ])\n",
    "combined_csv = combined_csv.drop_duplicates()\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"Professional/predicted_claim_spec_synthetic.csv\")\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)\n",
    "print(\"#\")\n",
    "all_filenames = [\"Out/Professional/Anesthesiology.csv\", \"Out/Professional/Counseling_Psychology.csv\", \"Out/Professional/Emergency_Medicine.csv\", \"Out/Professional/Nuclear_Radiology.csv\", \"Out/Professional/Obstetrics_Gynecology.csv\", \"Out/Professional/Ophthalmology.csv\", \"Out/Professional/Orthopaedic_Surgery.csv\", \"Out/Professional/Pathology.csv\", \"Out/Professional/Pediatrics.csv\", \"Out/Professional/Psychiatry_Neurology.csv\"]\n",
    "final_df = pd.concat((pd.read_csv(f, header = 0) for f in all_filenames))\n",
    "print(\"@\")\n",
    "final_df.to_csv(\"Out/To_s3/all.csv\", sep=\"|\", index=False)\n",
    "final_df = final_df.sort_values(by=['ClaimID'])\n",
    "final_df = final_df.sort_values(by=['ClaimPaidDate'])\n",
    "final_df[\"Date\"] = final_df[\"ClaimPaidDate\"]\n",
    "final_df[\"Date\"] = final_df[\"Date\"].astype(str)\n",
    "final_df[\"Date\"] = final_df[\"Date\"].str[:7]\n",
    "final_df = final_df.drop_duplicates()\n",
    "strBucket = 'data-science-synthdata-dev'\n",
    "out = final_df\n",
    "print(\"!\")\n",
    "out = out.drop(columns=['Date'])\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "c = \"\"\n",
    "print(\"%\")\n",
    "for index, row in final_df.iterrows():\n",
    "    j+=1\n",
    "    if not (c ==row[\"Date\"]):\n",
    "        c = row[\"Date\"]\n",
    "        if k!=0:\n",
    "            print(i)\n",
    "            strBucket = 'data-science-synthdata-dev'\n",
    "            strTestFile = \"Professional/Month_\"+str(i)+'.csv'\n",
    "            strOutFile = 's3://{}/{}'.format(strBucket, strTestFile)\n",
    "            out.iloc[k:j-1].to_csv(strOutFile, sep=\"|\", index=False)\n",
    "        k = j\n",
    "        i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821d2d6",
   "metadata": {},
   "source": [
    "dfPaid = pd.DataFrame.from_dict(paid_dict)\n",
    "dfPaid = dfPaid.reset_index().rename(columns={'index': 'combo'})\n",
    "dfPaid[dfPaid['combo'].str.contains('4256F')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d30c8",
   "metadata": {},
   "source": [
    "fold_lst1=[\"Out/Professional/Anesthesiology_provider_file1.csv\", \"Out/Professional/Counseling_Psychology_provider_file1.csv\", \"Out/Professional/Emergency_Medicine_provider_file1.csv\", \"Out/Professional/Nuclear_Radiology_provider_file1.csv\", \"Out/Professional/Obstetrics_Gynecology_provider_file1.csv\", \"Out/Professional/Ophthalmology_provider_file1.csv\", \"Out/Professional/Orthopaedic_Surgery_provider_file1.csv\", \"Out/Professional/Pathology_provider_file1.csv\", \"Out/Professional/Psychiatry_Neurology_provider_file1.csv\", \"Out/Professional/Pediatrics_provider_file1.csv\"]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f, header=0) for f in fold_lst1 ])\n",
    "combined_csv = combined_csv.drop_duplicates()\n",
    "\n",
    "\n",
    "strOutFile = 's3://{}/{}'.format('data-science-synthdata-dev', \"predicted_provider_spec_synthetic.csv\")\n",
    "\n",
    "combined_csv.to_csv(strOutFile, sep=\"|\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
