{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyGreSQL\n",
    "# !pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pgdb\n",
    "import pickle\n",
    "import zipfile\n",
    "# import nbimporter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "# import ProviderPredictionScript\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How many providers do we want to synthesize?\n",
    "\n",
    "## User defined for each specialty\n",
    "num_providers = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Probability of number of claims per provider\n",
    "\n",
    "### We'll eventually bring inference (of number of claims for each provider) from all customers for each specialty.\n",
    "\n",
    "### Based on MonteCarlo simulation from the empirical data\n",
    "num_claims_df = pd.read_csv('num_claims_df.csv')\n",
    "\n",
    "\n",
    "num_iter = 10000\n",
    "num_claims_avg_lst = []\n",
    "for ii in range(0, num_iter):\n",
    "    num_claims_avg_lst.append(round(num_claims_df.sample(round(0.1*len(num_claims_df))).num_claims.mean()))\n",
    "dist_mean = np.round(np.mean(num_claims_avg_lst))\n",
    "dist_std = np.round(np.std(num_claims_avg_lst))\n",
    "group = [int(round(x)) for x in np.random.normal(loc=dist_mean, scale=3*dist_std,size=num_providers)]\n",
    "scipy.stats.describe(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determine probability of different combinations \n",
    "### We'll eventually bring inference (of number of claims for each combination) from all customers for each specialty.\n",
    "all_combinations = pd.read_csv('all_combinations.csv')\n",
    "sel_combinations = all_combinations[all_combinations.prob_claims>=0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cdeb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique combinations and corresponding weights\n",
    "comb_list = sel_combinations.drop(['num_claims', 'prob_claims'], axis = 1).values\n",
    "weights = sel_combinations['prob_claims'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  \n",
    "final_df_list = []\n",
    "random_outliers = random.sample(range(0, num_providers), int(round(0.01*num_providers)))\n",
    "for ii in range(0, num_providers):\n",
    "    if ii in random_outliers:\n",
    "        tmp = pd.DataFrame(random.choices(comb_list, random.shuffle(weights), k=group[ii]), \n",
    "                       columns = sel_combinations.drop(['num_claims', 'prob_claims'], axis = 1).columns)\n",
    "    else:\n",
    "        tmp = pd.DataFrame(random.choices(comb_list, weights, k=group[ii]), \n",
    "                       columns = sel_combinations.drop(['num_claims', 'prob_claims'], axis = 1).columns)\n",
    "    tmp['ren_id'] = 'prov_' + str(ii)\n",
    "    tmp['prov_claim_id'] = ['claim_' + str(x) for x in range(0, group[ii])]\n",
    "    final_df_list.append(tmp)\n",
    "final_df = pd.concat(final_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df['ren_id'] == 'prov_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5ba21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
